<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Java Performace]]></title><description><![CDATA[Java blog focus on performace and concurrency]]></description><link>https://github.com/BrahianVT</link><generator>GatsbyJS</generator><lastBuildDate>Tue, 07 Jun 2022 01:11:47 GMT</lastBuildDate><item><title><![CDATA[From monolithic to scaling a System]]></title><description><![CDATA[Scaling a System from monolithic to microservices Initial Design To understand  I will use a  example with a fiction example , acne books is…]]></description><link>https://github.com/BrahianVT/from-monolithic-to-scaling-a-system/</link><guid isPermaLink="false">https://github.com/BrahianVT/from-monolithic-to-scaling-a-system/</guid><pubDate>Wed, 25 May 2022 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;Scaling a System from monolithic to microservices&lt;/h2&gt;
&lt;h3&gt;Initial Design&lt;/h3&gt;
&lt;p&gt;To understand  I will use a  example with a fiction example , acne books is an online book store that sells books at acne we started small with web application connect to database standards set up  and that at th beginning worked great.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 355px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/1bf8552b46b6b890ebd85805d0fba5fd/526ee/1.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 46.202531645569614%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAABJ0AAASdAHeZh94AAAB70lEQVQoz3WSzWsTURTF8xe0OvNmJvPy0YWRKk2bLqo7kagUsV2EgDuLKEJrbEsjNZJiEw3Tr9DQJDW1NX7UUrVohVawiCDG0mzqRl0p6N/yk5mYEEUX593HvY/zzr3nukyvicfv+S/suvRJpFfWok86OU+bB2+bF+mXzjvn7pO47EPoGopQUIWKIlRUIZwodNEgMH1mLf7+4KBQaFVaEYZA1VVaDrSgu3VcNllvNMzN7DBxa5DxmRhxa4hEdpjeSBjN0PD4bYVmQ6Fu6vRFz5KZT5EtTTO3aJG4fZ1QTxcuVVOZKIyw8/0pL/bLPNtb4uWnMm++rXMrH0dRVae9OlmdcG51ksqP17z9uumg8nOb85cjtkLB2OwV1qqLzG+kyTxIsLB5h7VqkfFsjEAgQGd3Jx1dHQRthIK0H21nojTKw0qO/FaG4rbFk70CkYFztkLBjcIgG59LFHcyLL+fYendFM+/3CWRj9UUNpvjkxjSIFUe49FujtyrFAtbadb3i0Qv9dVm2H/xFOnVUZL3YyTL10iuXGXy8Qj9A2ccw5wZNrfs1hmyLlCuzrKyO83yxynufbA4HTlRc9l+4JYGbun+A3a+4XKTw/W1CR47wvFwNz0nQxwOHnLyruZW/oW/682kuqEjNM3pwjANZw9/AeVZP8RVtaCrAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;first version&quot;
        title=&quot;first version&quot;
        src=&quot;/JPerformance/static/1bf8552b46b6b890ebd85805d0fba5fd/526ee/1.png&quot;
        srcset=&quot;/JPerformance/static/1bf8552b46b6b890ebd85805d0fba5fd/c26ae/1.png 158w,
/JPerformance/static/1bf8552b46b6b890ebd85805d0fba5fd/6bdcf/1.png 315w,
/JPerformance/static/1bf8552b46b6b890ebd85805d0fba5fd/526ee/1.png 355w&quot;
        sizes=&quot;(max-width: 355px) 100vw, 355px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;Initials problems&lt;/h3&gt;
&lt;p&gt;When we had a few users the user base kept growing we got more and more customers and occasionally we ran into some performance problems in the web application we solved this by adding more instances of the web application to increase the availability and solving the issues that way this worked great for a while.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 365px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/6f2f7b094f7d81d593314c5d0ac35993/2e8d1/2.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 38.60759493670886%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABJ0AAASdAHeZh94AAACAUlEQVQoz02S7UtTcRTH739g7t7du3vnNt3U0GUQBIVvDEykYIW9ME1IQo0IDOpF1iof1sSZc+rmMufTNmc+4SJtQgRu6jKTfBH+QZ+4Vx29+HDO75wvPw7fc4ThRC/vY6/wz7zGF+vhQ7KX280NFIsmrA4raomKZtPQbKfx/G21n/YUTcFitZxpNIT08Ryrh9OsHcZY/RVj7XeMxVyUm546ik2nn56LC5RoiLJk5K6LLkpdDsyKGVlVEJJ7YRLZCMnsJKndqMHn/SkSOxHqPXWYJNGYTp9CR7WqyKrMszdPWc4kWN1eZGU7yfRyhNob1xDi+THmd8ZJ5aPM/RgjuhkgnguzfjzLo+dtyIpCWXkpDqejgL3MRjg9yNbfJdJHcdJHCbZOUtxr9yDM5AMs7I3yMTPE0KKXwXgP418GSB5M8LC7GafLhftyNVWXqgzcNdVUVlXgT77k0/cAo+u9hDb6md8N4WltRGh63Mjsz2HmDkaYyg4ysx9gOjfEyskkD7qbKCq6UDBfR/dJsSqMbHhZyAcJZwaIbPtI/ZngbvstBMkscaejgSf+Nrr6Wujsb6Wzr4Wu/lau1NagWBRjo/8vRfey4919gl+9hL69Jbjpxbf0guv1VxE0u4ZkNmMSxTMkRFEyctmiFE5FtamFk9GjbJEprbBTWVNOhdtp1HX9P9UfQD7FAgq7AAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;second&quot;
        title=&quot;second&quot;
        src=&quot;/JPerformance/static/6f2f7b094f7d81d593314c5d0ac35993/2e8d1/2.png&quot;
        srcset=&quot;/JPerformance/static/6f2f7b094f7d81d593314c5d0ac35993/c26ae/2.png 158w,
/JPerformance/static/6f2f7b094f7d81d593314c5d0ac35993/6bdcf/2.png 315w,
/JPerformance/static/6f2f7b094f7d81d593314c5d0ac35993/2e8d1/2.png 365w&quot;
        sizes=&quot;(max-width: 365px) 100vw, 365px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;Vertical Scaling&lt;/h3&gt;
&lt;p&gt;We got some more performance issues web applications stopped responding and this was caused by slowness in the database we didn’t really find this strange the database was used on every page it was used for everything so obviously if the database was slow the web application would be slow as well we solve this by buying a larger database from a very expensive database vendor.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 457px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/9813c385178abf00e42803d7f90749e8/34f1d/3.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 43.0379746835443%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAABJ0AAASdAHeZh94AAACPklEQVQoz12S60+SYRjG+RcyeF9eQEwQQWipaTZ1ummH2bQsW0mrNV0fytz6YDUsD9OSBCVR5DDUpCmWNWflYSiKgK51Wsv+ol/jhdbWh9+uZ8+e+9p9P/elsJZZsJwwU1JqodhmQlALaPQaNPkapHwJSSfJZ1GjRleg4+Tpcs41N9LafpEr9ks0tzVR21BNsdWEIAkowjEPwXU3oY0xAmsuGlrqOJKXh1avlY2yZiJFJUYCUS87PzZJHcZJ/97Jchgn8TPG2v4KV29dRhFJThJJ+ogkp1g8CDC7PUF9Uw0qUSV3mDFUCipsFRaWDkK8Sc/wNvWK9+mIzLv0PNFEmE+/Frn7pANFOD7G3O4EoU03vg9Ool8COF4+QJTU6Av1MpJWw/FKK8GYi5mdceb2PMzmmEt4CG25WPjso6PHjmJ230Vwe5QXS09wRnuZSY7xyNOFwWjAYjPLGE1GKmrLCe+6mV4fYTTax/hyP+PLA0ysDOHfcLL01U/nQzuKGz2teGMDuFcdMlPxQe702TmqVCLp1PJSlCol5jITwbgT78dBHL5uHk/ew+G7j8PXhWe1n4VvXm73XEORKbBWmLFVWrJ6ykJBUWbM7P9lliOIAtZKM6HkCIHEc1kzBHM6tTXE6+8eOnvbUWSKBLX4D1FArVVnY/M3MpIaQ8kxns53M703hD85TCA1TCD9DH9qWL6b3B7gws3GbIdy3nJoctn7H1ES0RVqKa22UddSxdnrdZy319PQVkPVmXKKbAb5zR84tHlkOEME/AAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;3&quot;
        title=&quot;3&quot;
        src=&quot;/JPerformance/static/9813c385178abf00e42803d7f90749e8/34f1d/3.png&quot;
        srcset=&quot;/JPerformance/static/9813c385178abf00e42803d7f90749e8/c26ae/3.png 158w,
/JPerformance/static/9813c385178abf00e42803d7f90749e8/6bdcf/3.png 315w,
/JPerformance/static/9813c385178abf00e42803d7f90749e8/34f1d/3.png 457w&quot;
        sizes=&quot;(max-width: 457px) 100vw, 457px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;Migrating to microservices&lt;/h3&gt;
&lt;p&gt;Business was good and books sells were really high so we could scale the database one or two more times after that we discover that web problems about developing this application was by the monolithic approch so after some analysis and maybe some hype,  we switched to microservices to be able to scale each individual service and to be able to scale development over several services as well.&lt;/p&gt;
&lt;p&gt;We developed  something like this this is a small part of the system we had our web application which our customers used to browse and buy books connected to some services :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A service for displaying a page with special offers.&lt;/li&gt;
&lt;li&gt;A service for listing the products that we sell.&lt;/li&gt;
&lt;li&gt;A service for making payments this service is run on separate machines made over the wire calls between them and each service had its own storage to to allow to scale storage separately.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 251px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/b41752231bc9ab43c5b782b6605d2a8c/26abe/4.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 79.74683544303798%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAABJ0AAASdAHeZh94AAADJElEQVQ4y42T/W8TdRzH+x+wPl571123lnZ9vK7rtde5LYT5QNSkCGyVODZRtIhz4xft2JhoJ4490S2RkOl2nTwYYqDzYYGEJZogAhrB+YPGP+dl7roqRhP2wyvvy93l/f18Pu/P1yI2izwRr8dUz7a6PAIOlwOHy1lXwYnd6cAtubHsyHDbTJIlXG4Xak+KUwujjC2MmIxXTnKyXCQQan2yoWHUqMxgV5OVwlv7Wd+q8umtefTNCvrmIjce6qRzSSziYz//n1nj2eVx4fPLJBSFgZGDrN2tMLX6LmerJZbWy1y6u0RKU+oVSj7pX3h90t9GxlwMs0g8Qq5Lo7lZZt8re1j7eYHFjTPMro9zYbPMZ3dmiKcjWDySB6vdhtVmo8lqNdVA8Aimkdwqo2oqyY6kWbHxXpJFomqIRC6C0hlByUUJKQHzu8UXkBkc6efExFFOnD7K8fEhjp8aQlHjtEXa0J7SCAT9ON1ORFnE5Rbo6FQY/bDI8OQbDE8eY+TMmxRLr9JqhKJko9S2Vrn2YJnljVmu3PmEm39epXDsJfwBP80tXgRRMBM2RmGz2ekv5vnm98+5/ssKNx6uUHu0yldba6Ry7ViSWpTl27Ms1spM6SXmrk2if3+eQ6/l2R0Mks6myWgqalYlk8uQTLYzMNrHxVvTTF+eYKpa4uNLY+jfnSdlpJzIhln4epLpL8eofPs+8+unuXD7I/JH9hGJRgmE6u2ae7hd4fODvXzx2xL6/TmqD+ap/jSPfm+OhBrDYgy464UMT/d1s/dAF70Hu+k90E1rqMUMxKgqnoybaQuSYCbvbZGIZduIa2HiWhuJzjDh1G48XhGLcbLD6cRud2B3/INhYJqIArFEzGzbH/Rjd9qJpcIcGe5n4O06g+8U6Ht9Pz6/b3sPZek/PL7gjfXJ5FSCoRCFYp6NPy6bYdQe6SZGKB1a+86uXmPBDYLBEEOj/VRqH1BefY+ZKxOcXStx8eY50p3t9ZZ3QuNGNe1q4sXBvVz9dZGVH86h35tFvz+D/uMciUxs54YN3KKbQKSFZwrdPPtyj6nPHe5hTz6H5BP5C1+iK3G3Mn0vAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;4&quot;
        title=&quot;4&quot;
        src=&quot;/JPerformance/static/b41752231bc9ab43c5b782b6605d2a8c/26abe/4.png&quot;
        srcset=&quot;/JPerformance/static/b41752231bc9ab43c5b782b6605d2a8c/c26ae/4.png 158w,
/JPerformance/static/b41752231bc9ab43c5b782b6605d2a8c/26abe/4.png 251w&quot;
        sizes=&quot;(max-width: 251px) 100vw, 251px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;Problems appear again&lt;/h3&gt;
&lt;p&gt;This worked great but one day the web application was not responding customers, they couldn’t buy any  books we restarted the web application it helped for maybe a minute but then it became non-responsive again , well the web application looks healthy enough but we notice that the special offer service has stopped responding as  well okay that’s no big deal the special offers are in a separate page then just nice to have functionality but if the special offer service is not responding and it  shouldn’t cause the total web app point of failure.&lt;/p&gt;
&lt;p&gt;Okay we continue digging the special offer service is calling a third service a purchase history service to show special offers tuned to the customer’s purchase history and this service has stopped responding as well we had encounter a cascading failure where the failure in this purchase history service had cascaded back to the web application a failure in one part of the system have affected other parts more critical parts if our system so if we compare this to the database case with a database failure affected the web application this is so much worse, because this service is not-critical and it´s stopping the entire system.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 389px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/9df8245a4e04a400e8fda11588261245/00a4e/5-6.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 52.53164556962025%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABJ0AAASdAHeZh94AAACRUlEQVQoz3WSa0sUURzG5yvk7OycObOzV529qBlW5gXU3BLMXQnEW7URYpSWL1RCtMTVWNaCDNeCFTKz8oIiRAjRmwhf1Mf6xczuRoi9+HE453/Oc57/RZGWxMXnYGBU9pbEa+i0dTdz816adKaPZLoT6ZcIn4GwJIZl0JVup/dWDzdGUrRcbUKR/wiUhA13dYSF0FjZeMLu5jyft59S/JInHq8mIHWCUmDHQxT3l9han2LvYJncuzkUwxQIKTDMkpAoi0UtSUTXePZmnK3iBEcbGdYOZknEIlRLQY00iMeCFPZn+bg2yvH+Q7Kb0yhW2E/QDmGFLDeVgE+S8EkilkQzdC52NHB9uJPkYCet3ZfdO7olXYRl0HStkbZUM22pFi601qOsv59nOT9JYS9Hd6qdoKriD/gw/CZeXWNycYy1gxyru8ssFGYIVQcRpsAsl8fj8aCqKlWqiub1ohwdZjnMjfDjJEf/g37C4QiJ8wnqG+qw4zb5nTk+/S6w+fMVxe8viNbabrMqNTf9JmagjF+ijD+/zVR2iKmVDFeSl4jGokTsiOtC07303u1ibHGY0YVBBh6lsII+jHLjKpMhrRJO7RVV83BO06jyePAKr/tjvC5Ooj7hiib7Osg8HuLOxAB9Iz1uvCLorKdRXMtl286MOYe61F2XsUSM/PY8O7/esn1SoHj8Eru2Bt1J2X9q3MooZ/3ijo+vlPLM6n0K37K8/rrA0odpQnYIXYr/O3TSOouSU0E4FiTRaLvU1IX/xhzOevcHuIlpBx9VJCkAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;problems&quot;
        title=&quot;problems&quot;
        src=&quot;/JPerformance/static/9df8245a4e04a400e8fda11588261245/00a4e/5-6.png&quot;
        srcset=&quot;/JPerformance/static/9df8245a4e04a400e8fda11588261245/c26ae/5-6.png 158w,
/JPerformance/static/9df8245a4e04a400e8fda11588261245/6bdcf/5-6.png 315w,
/JPerformance/static/9df8245a4e04a400e8fda11588261245/00a4e/5-6.png 389w&quot;
        sizes=&quot;(max-width: 389px) 100vw, 389px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;Debugging to find the error&lt;/h3&gt;
&lt;p&gt;What happened when the purchase history survey stopped responding and affected all the rest of the system we sorted look at the web application because that is the component we want to save we’re on a standard web container for the web application contains a &lt;strong&gt;thread pool&lt;/strong&gt; with a fixed number of threads the &lt;strong&gt;blue boxes&lt;/strong&gt; on this imagery illustrates the threads and when the user wants to use a page a request comes in it is assigned one of the threads from the thread pool.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 111px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/8642237f51af0ef9f4d66979882e35ad/a4766/7.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 213.51351351351352%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,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&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;seven&quot;
        title=&quot;seven&quot;
        src=&quot;/JPerformance/static/8642237f51af0ef9f4d66979882e35ad/a4766/7.png&quot;
        srcset=&quot;/JPerformance/static/8642237f51af0ef9f4d66979882e35ad/a4766/7.png 111w&quot;
        sizes=&quot;(max-width: 111px) 100vw, 111px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The thread in turn calls the special offer service we want to view that page makes a synchronous call and wasteful response.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 364px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/43daff38c24a6d7a56279cc18cdb969e/e45a9/8.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 64.55696202531645%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAABJ0AAASdAHeZh94AAACY0lEQVQ4y32SW08TURSF+xMotHOfTjtQegEBoxAlmgjBF8XEByXGN/DJ6INK0ASDEAQsAQkqpYU2CFourVVAIBJjYjQxmpAY8fYPeOM/fGamlFuEh3XOZM7e66yz9nLImoziUVB0BftbV7YhqSJ3+q4zmOomMtlBV/QumldDVvfW7YbDWgRJRFSkfWQSuk/j0fP7PJuP8PRNhPjSIGbAh6iIBxNajeGqACUhE0EWd1Rau08lHm/nW+YJXzPDpF8NYAR8SFuX52tVj7oFW6FMdLmDW73NyLKCUWzY6iRZRPAqzI094Fc8wo9oH+9eP0YrNewzi8B+nSzicrtwCS7cojun8NyVOmobqvGaPsoryyirKKM04Efze5ge7+R3KsafVIzl+WHMcj+KlrNEkAXCR4OcrK/hxJnjHKutynnoLCzCJbiRNMn2UvfqFPuL7eJYop/syjqzi99JLySorKkgGA4RPhImVB6ic7SViffDRBcjJFeHcFg+qEbu/XljrX+iLCF6BEbGI6RW/jL19icvs1H0EtWesmEaeHw6vdNtjH/oZyDbwczaiEW4l2h7YqqCbCok4l18yS7zaW6BTGYII+i1h5K7VORs02mu3r7I5ZuNNN24kFO4HzlCGcFUmRltY3Oqn41ED0vpHrSAF3lXxIqKXBQUOHE6C+3dcVCe8oTT0VY2JyNsJB/yNt2NFvBtE+bt0nbhUIWiqZAcucf6iynWJpJkZnvQglZsdgj347+ENhQZ0SsRG2vn89IqHxdWmMlG0Ep1O4cH9dk5PAiCItLQWE3LtXqaW+o4f+kUkiZzWM8/K4a3Ndq8dg0AAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;eight&quot;
        title=&quot;eight&quot;
        src=&quot;/JPerformance/static/43daff38c24a6d7a56279cc18cdb969e/e45a9/8.png&quot;
        srcset=&quot;/JPerformance/static/43daff38c24a6d7a56279cc18cdb969e/c26ae/8.png 158w,
/JPerformance/static/43daff38c24a6d7a56279cc18cdb969e/6bdcf/8.png 315w,
/JPerformance/static/43daff38c24a6d7a56279cc18cdb969e/e45a9/8.png 364w&quot;
        sizes=&quot;(max-width: 364px) 100vw, 364px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;When all is ok the service returns the user gets its response rate but when the service is not responding then the thread will wait for reply and while waiting for the reply it will be blocked it can’t handle any other requests.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 351px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/4bdacc05ce661fb5828ad6cfb3171535/7c2a6/9.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 65.18987341772153%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAABJ0AAASdAHeZh94AAACgklEQVQ4y32S20sUYRiH9w/o4H4zs7vzfTOrGxTaAQKJzsWueSgoHSOiG2sRPBSVFAWl5u4WdZEapHmqi9QLTTqp1GZkRnWREEHiRdRFdd//8MTM7tpB6+K5et953u+d3+tTlomyJKYtkZaJtE1UWOHXBMdb4gxOd3N9OMHwTA87y7aj6ZpXl5ZE2ovx+W2JbmekmaaMUDM0mq7U0z/ZTudIirsvuiivLsEvBCr/P8KYMtlkZaRmFiusWKkLLqXqmb/fzYfBDmbTfZQ6MU9o5StMbxvpDc/hCaeCITqU2yCJ5KaGFct0weUrjXwe6+Vt11Xmnt2mtDq6IHT7QjKE0DWEJjwCZhBfuTLZYklv5UJLUuQSVhiGxuVkHV+7Esy1nuLj6HVKqmPkeStbBFSIVYWriFXuJuZE2VMVY93Gol//0F01aJteMJGwwjJ0Eq21zDbU86zC4eW1czhOlIgQrI/YWELg1FRwb6qTgZ7zPJjuprE5ji+XssxiZldervu5mDrBw1ef6E9/ZXImzd7KbQhNoyBio/yCg7UVjEwkudN8iNdPz9GQjOOTCzJzITk3lDxD0JKsY/bxBOnBR7x+OsQeZwd+oWEVWOihIGs3FXL49H6O1JVR07SfzbFifG5avyNzKRsabYk4P0Y7+d6bZH7yBlFnFyJ3NrYkaAa9AX5dJ09oGMEAvsW3lBGuMERGONLOt1sJ5ic6skLNEy6cTX7mZLzkw3LxC10yLxQ0tx3ly+gA7/u6eTd+k6iz4w/hUiwpVLZkpe7nQuoYb548Z3xsmumpIUqqtnorqrD8tzCkQvyNW9ACBrvKizlztpKmk/uoP32ANRtWEwgGvPpS37n8BOc+tfHyL5dPAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;nine&quot;
        title=&quot;nine&quot;
        src=&quot;/JPerformance/static/4bdacc05ce661fb5828ad6cfb3171535/7c2a6/9.png&quot;
        srcset=&quot;/JPerformance/static/4bdacc05ce661fb5828ad6cfb3171535/c26ae/9.png 158w,
/JPerformance/static/4bdacc05ce661fb5828ad6cfb3171535/6bdcf/9.png 315w,
/JPerformance/static/4bdacc05ce661fb5828ad6cfb3171535/7c2a6/9.png 351w&quot;
        sizes=&quot;(max-width: 351px) 100vw, 351px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;While waiting for the reply it will be blocked it can’t handle any other requests okay so for no big deal where one blocked thread the other threads can still be used for other stuff our users can still browse products and make payments so they don’t notice anything yet but as more and more requests to the special offers page come in more and more threads will be blocked until eventually all threads will be blocked.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 403px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/bf19c70471e15d0b59cb26e0ec0ced3b/045fd/10.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 56.32911392405063%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABJ0AAASdAHeZh94AAACf0lEQVQoz2WSW0tUURiG5wcU5sx2t9dae83oSHkgy1PSUSwwpAxKyzFNTDE0xFOncUazwlLDI53GJKduJuyiNG/CuowoqK6Kki668Kp+xRN7zxRhFw9rwfp41/u93+fxaYmDsAXSlkgtUX6F1/DRHm1m9uUUM4tjDM9F3Te3Tsu/d8M08Pq8LqYw8ZwXgm6VFDW1wEoJ+kyDrnAzyy+mWXo2yXgsggrYCCUQWmJpgbAlpfuLKa/eT/nhcvJ25OI5Jyw+WoJeJcm1JVvspOAG08dApIXVxG0+z08SnxvCDCjXVUBLcqRFSbafu0+v8eRRlOWVKdojzXjSbUGbFDQpSZktqVKSSq0oyDC42n+Gbw9v8TU2Qvx+hKyAYpsSlNqKYinYGfQzdLeDqeshFuKtNHQdx+Nkka4lXi3Y7PxuS7ZrRZmZwY2+Bj4dPcT7ir3MRlsoyvJTKAW5jkPb6UhQeaKCUGcNoc5aSvYW4pG2QKWQbjYSyy/ZaGXQ31vPh/JdvC0sIHa5iZygH1sJMrVkqxL4g5rxxBDxVzMk3tyj7dJpR1C60xXumRS1/YpNpkH/xQZ+3LzA6kAnsYlujCybTCXIdz5VAh3UXJnvZnJpkDsr12nsqcHjhPwvfwTTTB+RcCO/nt9nLTHNg9nLBAKKvNSURWptdleWUlV30CW/KDeZ4Xr+Orx0ip+JCdbmR5mf6WFLasruDqZaHrzTx/TCMPcWx2joqP3foYPSkjTTIHqxju9nT/IlVM3scAubgxohrWTW0iKQrRldCBN7PcLjd5O0huvxWMpiPU6W3gyD6pp9TAw0Mh4+RXP7EUxlIdbVlh0souLYHg4c30NeUQ6/AT6of9GLLGUEAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;ten&quot;
        title=&quot;ten&quot;
        src=&quot;/JPerformance/static/bf19c70471e15d0b59cb26e0ec0ced3b/045fd/10.png&quot;
        srcset=&quot;/JPerformance/static/bf19c70471e15d0b59cb26e0ec0ced3b/c26ae/10.png 158w,
/JPerformance/static/bf19c70471e15d0b59cb26e0ec0ced3b/6bdcf/10.png 315w,
/JPerformance/static/bf19c70471e15d0b59cb26e0ec0ced3b/045fd/10.png 403w&quot;
        sizes=&quot;(max-width: 403px) 100vw, 403px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;When all the threads are blocked when additional threads come in they are in queued and this is a really bad situation because even if our service would be would recover and the threads would be unblocked we still have to handle all the queued requests so we really want to avoid in queueing requests okay now we understand what’s happening on quite a low level in our application but the question is why.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 404px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/c7ebac1e1b9da8379394e08802cfdb9d/494f9/11.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 57.59493670886076%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABJ0AAASdAHeZh94AAADDElEQVQoz02T7W9TZRjGz2cTXXt6enbe+37arpSutpx1hm5YFsogAwWzle5FrFMYI0qjMegI0imbE4cLo0DUEBaiElEa0Gj0gyC4xBg0fpNEv6jx7/iZc0Tihyv38zy5X64r9/UIiq6gmRqqoXpRt3QkOUjp8SIvnTzE4blnmT3WIJaM0q11ezmaqd6PGnpI92rc6N6FUMRCVuUHCUbIoMvvY9/BPVz+/gIrnbe4fPsChf48kix5xR4BU0VWZPyiiBhw4cclJ8wcPEAkHvGmuw+6pdEl+qk9M8Ktq6e5ubbE9c+WyfXnCMpBj52rRtEUNpULPH90ksbLU0wdmSCeiiLMH3+difFx0pk0yXSScCzMw74upqZ389un5/lxdYEfbrTJ9me9huFYCLvHxrZtpppjdG4scmVllus3l3EqDkKh1EfeKRJPJugtPIpTckim0jw3O8q9c/P8Mtfk9odLFCsOsViUbG+WDbkNJGyb7bUKrZVpll4bYam9n3Qxg7ASlNityAR1BctQMWMhlHCYxgtj/FzfxR07yecnZiiPVEgk4iRSCU9FNB6lty/LZLPGeLPO6IG9RBJhhOO6RtXUMQ2NHkPDMTUqXT7mntzC3doI66k0X7QO4VQ3oyjd3lLstI0UDLKnsZOrd9/j0rfv8tF6G2eggPCmqjJsaF7DlKGRsQxsUWRmosrvZ47x69HD3FprkenPIstBkj02VsREDASojg3yTmeO1lqTkx+/Qm8pi3BGVdmr63QbGrqhooZ0HhJFRqd38ndnlT8vnmL92ik2bs4RiUYww+aDLcfSEbY+MeBhYMdjGGEDwWdqSK4V7vvQDOn4RJF9jWH+urLMH+fe4M4ni2za2oeiKJ5tXBOLUoAdtSHe/2qZ1WsLnO0ski/lEFxWmvGvt1wYls4jfj/16WHuHZnkp6FBvj79ItnBPJIUQLM0z6uu5F1Pb+OD795m9ct5zn+zQLGcR3DN/H+4DERJolwt0p7fT/vVOq0Tk0QzMe9n/DfYPdsb42yvb2FbbZChp8pYUZN/ADDGqTwGK+DzAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Eleven&quot;
        title=&quot;Eleven&quot;
        src=&quot;/JPerformance/static/c7ebac1e1b9da8379394e08802cfdb9d/494f9/11.png&quot;
        srcset=&quot;/JPerformance/static/c7ebac1e1b9da8379394e08802cfdb9d/c26ae/11.png 158w,
/JPerformance/static/c7ebac1e1b9da8379394e08802cfdb9d/6bdcf/11.png 315w,
/JPerformance/static/c7ebac1e1b9da8379394e08802cfdb9d/494f9/11.png 404w&quot;
        sizes=&quot;(max-width: 404px) 100vw, 404px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The code that calls the services looks something like this in this case we create the URL to the special offer service we create a URL connection we open that connection connect it get an input stream and read the response from that stream , but what &lt;strong&gt;why&lt;/strong&gt; doesn’t this return, well we realize that connect and read time outs in Java they are typically infinite this will block for an infinite amount of time. &lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/68f40039b249e9fd80a6af6d255d770f/47ff6/12.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 20.253164556962027%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAABJ0AAASdAHeZh94AAAA10lEQVQY00WPPXaDMBgEuYZtwAaB/j6EhCCI5yLx/S81eZAixTRb7O5UMQWUcTyVwjrNFCbmGNHWoq1BjQPGWYw1eBFGPeLF4bzDOMOgB0Yzoo2mUx3VthfSujPnjbyupJyRfGDnFeUj3aDotUVCYNsyaUnEFC/CHGieDffmTvtqqNuaSpadfHwTv96kbaeUws/nQzkKThyPtqEeNC/taAeDdpZpEvzkkSAX59Oz9FbfqET8tRxjYF0zOWdSSteTZUmXvpGZuu9pesVo9J+i/dc9s7p9XIW/GM522I9u+HMAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;twelve&quot;
        title=&quot;twelve&quot;
        src=&quot;/JPerformance/static/68f40039b249e9fd80a6af6d255d770f/f058b/12.png&quot;
        srcset=&quot;/JPerformance/static/68f40039b249e9fd80a6af6d255d770f/c26ae/12.png 158w,
/JPerformance/static/68f40039b249e9fd80a6af6d255d770f/6bdcf/12.png 315w,
/JPerformance/static/68f40039b249e9fd80a6af6d255d770f/f058b/12.png 630w,
/JPerformance/static/68f40039b249e9fd80a6af6d255d770f/47ff6/12.png 852w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;Stability pattern&lt;/h3&gt;
&lt;p&gt;If the service never responds this made us realize the first stability pattern use timeouts, timeouts prevents blocked threads we first are timed out of course I timed out our threads can do other stuff in this particular case we could set the connect timeout.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 421px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/ca79447b29e64f5072c705fae357d272/092ed/13.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 26.58227848101266%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAABJ0AAASdAHeZh94AAABB0lEQVQY0y2QWXKDMBQEuUNssxiDWYQWhMRiIDip3P9WnULJR9d8vak3HY2T57VtKOvprWHdXwzjTO9n9DAipERqg7aWafaM84ibHNMyBaTuqEVN0zW0siWq+xZzOPRuUatFLIa7UxTzQDmdaHInqfYBszl0r1G9QhoZsqxKkntCmqeBKG4LkkmQuJbY1uS+odg7iqUl9U8S/yRbKhKTc8uuXOMLH/GFyz+39EacxaEse2REsrcsxw/DvDKun6zbi/f3m+PrwI2O8lnwqAXPzlC0kkYp+sFg/lFGhSzr8u/Dc/vpYvA2cDqyzmK9xc8+TNPOU4qOvKqphAjehBKB877THWVVhMJfsg2Rt99DtlYAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;thirteen&quot;
        title=&quot;thirteen&quot;
        src=&quot;/JPerformance/static/ca79447b29e64f5072c705fae357d272/092ed/13.png&quot;
        srcset=&quot;/JPerformance/static/ca79447b29e64f5072c705fae357d272/c26ae/13.png 158w,
/JPerformance/static/ca79447b29e64f5072c705fae357d272/6bdcf/13.png 315w,
/JPerformance/static/ca79447b29e64f5072c705fae357d272/092ed/13.png 421w&quot;
        sizes=&quot;(max-width: 421px) 100vw, 421px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Great we introduced timeout at Acme books, timeout for all the service calls things work great for a couple of months perhaps some services that became slow and didn’t respond but the timeouts saved the rest of the system but one day we had to fire again, customers complaining going to buy books had terrible response times, now web application we’re awful throughput okay what’s up now have what we solve these kind of errors where the web application would be slow let’s investigate what’s happening.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 427px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/220a1f3d6ab4ce6adcd0d0fa30740cf9/a7c74/16.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 54.43037974683544%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABJ0AAASdAHeZh94AAACMUlEQVQoz42TTU8TURSG+wcISTszd+58dDotSD9sCzMFjaElKmCMccnChLgwQWFDorJhIRsjaABFjPELohEMIFAhwagk6pLQhSbq3oUrf8VjOhVBYeHiybmLk/e+5573hgzbQFqSag2IGmi6RsZL8uTtFJOLN5jdnKat6BNRFcyoudt7ACHdkkjLoFYl5o6gn+LZ2gQL67eZe32HQtH7P8FMwuRd/xG6/QYUQw8cKppG2k9RWb3H10fjbJWnKXT4KPsE5X7BeMzgclcaP+XQ4JpkGqM4lk6uLU3l5RTf7o9SKU/jdXhEFAUZNdEtA/F7oipCCoQhgnMwcp0mUKvubIntmLiWTuuxLNvPR/g+MUBlfoSOzgJxS+A6Bo6tk3AtLNvAcizi6QbiqURwDlVtWtGa3Z3lRIQg6yVYXl9lrvyFVxvLtJZyqEqYo615Ci0ZEjETR6pcHDrH3cfDTM1c48KVXkK7G5YYf5YiyPiNvF+dYWu+zMe1GVqKOWKuy8lTnRzvOkEqm6auvp6r430sPR3i3cIgw5P9NcG9BLERGkm/ic+LY/x8eJ1PK7fIl/LEYjHyXp5UJklTuilIQ3N7lu6eIqd72vHac4SkLdlLTVCQ9BupvBjlx4Mxtpduki81E46Eg8fXpBbU6mTVy8OKEqAK7QCHtkQVgrQX5836LB9WNtncmKWldBhFUYPY/N1f+wxmdCfYps6/VGNguSa9fWcYGOzh/KWzxA45wYgH9e/lF1FTaEsNKOjqAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;fourteen&quot;
        title=&quot;fourteen&quot;
        src=&quot;/JPerformance/static/220a1f3d6ab4ce6adcd0d0fa30740cf9/a7c74/16.png&quot;
        srcset=&quot;/JPerformance/static/220a1f3d6ab4ce6adcd0d0fa30740cf9/c26ae/16.png 158w,
/JPerformance/static/220a1f3d6ab4ce6adcd0d0fa30740cf9/6bdcf/16.png 315w,
/JPerformance/static/220a1f3d6ab4ce6adcd0d0fa30740cf9/a7c74/16.png 427w&quot;
        sizes=&quot;(max-width: 427px) 100vw, 427px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Thee timeouts seem to be  working well but we notice that the service is called a lot more often that then it usually is, there are a lot of timeouts in fact there are so many timeouts, that it seems that our threads spend most of the time waiting for these timeouts they don’t do much other work at all  so our throughput will  go down , we get a throughput that is lower than the number of incoming requests so say that we have a throughput that  can handle 30 requests per second we have 40 requests per second in coming to the to the web application we can keep up with the load and this will cause requests to being queued .&lt;/p&gt;
&lt;h3&gt;Bulkheads&lt;/h3&gt;
&lt;p&gt;The pattern isolates components from each others to prevent Falls in one component to affect others,  then prevent cascading failures an example of a bulkhead would be to limit the memory usage the allowed memory usage of a process so if it would show a memory leak then it would be allowed to just use up a certain limit and would not eat up all the memory on the machine.&lt;/p&gt;
&lt;p&gt;Limit the number of concurrent calls to a service limit the number of calls from one service to another this will put an upper bound on the number of waiting threads so I will talk about this a bit here if we if we have the web application and the special offer service we can add the bulkhead of size say 2 in front of this service between web application and the special offer service but only this we are saying we will allow at most two requests concurrently from the web application.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 310px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/d640507c1ec1adeb1607a367354b8c01/5fad2/17.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 77.21518987341771%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAABJ0AAASdAHeZh94AAADPklEQVQ4y4WU3W/aZRiG+ydYvr8ZMdLGaJbogYkHPfFwdXXJ3FqLdG3XGWOia/qBa9lKaaFAYR0wVuDHoECgsEIHWW1ThK5dt6ZxiZsxatREjzwx/g+XASqd2ujBnedN3uTKcz/3875tKp0KqULG6bdeY3isn6HRfj76fKClKxYzH08PcmG4B+0pDQq1EpVWhVLTrP9Um1JTv1Rgj0ySroXw5xxk9pa5dyg0lD8UyB1EKD1Lcn6wB5FYhFqvPhHWAMpVcl7uNDAXu8bNew58+Tm8q7PEtpdI1IIkdoLEq35yhwJXJgcQicWodf8BVKgUaI160mk7z0shnhYCHJSDpHaDxGt+ols+IhseMvshBkf7EEn+B6hUKdB06FiL2/g27GHfN8tXd92kdgMIlZu4klYciSmC9x2YP7uAWCo5Bmr+rSbQqKOQmOHnuIengRm+zy8R37lF/KGfQNmJP20lVvEyNNH/N8v1WWr06lZtWdYZtaTjDh4VvqCS32B3LU1iZ5FYzYdwEOTB0qcUtj1csphawHrKdfsvtbfTfiSZUl4HKtEbNcQSblKlrwkXnlEsllmpuRFqPqJ7S+SS18jv+Lg08QHiF2b4Tk8X54be5az5DO+Zu3n9jVePgZH4AunScyLFbygUysSrTqJVD5GHiyRzVjK7XgbGexFLJI3uDMZThB+4SGVuELlrpbgfwfTJ+02gtkNLMjbDQXaNSiLHXlZAqDmJVBe488THunuE3OYcH1r6mkC1EkOngeiGnej8EKvWs+xVp+i92nuccl6w8EfCxa8hGz+mnEQaQCd3nngpuS6T27QfAcUNuxqDhhF7H+OLZiz2i9hCI3R1v90Eqjt0rAqT/Lbi5aewg+/SCyzX5lmuznP7sYf7nstktmyYJi8iroeib4YikUkbQUhUSsRyGTKF7AjYqScbHuN3YZZfgtP8sGIjULU3FKzNsVyeJvbIgWnsfMNya23+qo3zCy9F/YqKmGBlK/sla8kKm+kEt7enuFW5gb9yHd/2daKHTkyj5xCJxNQ/lHqHJ6lNVd8nuYSR4W6yCQ8rgptkfAZXcQzn+jjO4jgL6xPMZq/yZtdpJFIpSq0ShVpxov4EZ31zL3hvjdkAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;eight&quot;
        title=&quot;eight&quot;
        src=&quot;/JPerformance/static/d640507c1ec1adeb1607a367354b8c01/5fad2/17.png&quot;
        srcset=&quot;/JPerformance/static/d640507c1ec1adeb1607a367354b8c01/c26ae/17.png 158w,
/JPerformance/static/d640507c1ec1adeb1607a367354b8c01/5fad2/17.png 310w&quot;
        sizes=&quot;(max-width: 310px) 100vw, 310px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We have a bulkhead or two of size two to the special offers service a bulkhead of size four to the product service and about eight of size three to the payment service from the web application and this way in this case we have an upper bound of totally nine waiting threads in the web application we’ll never have more than nine waiting threads do to slow services and this offers great protection against cascading failures our services can behave basically however they want and we are quite well protected but only if our bulkhead sizes are significantly smaller than they request pool size if you have a bulkhead when calling a service that is of size 40 and we only have 50 request threads in our application then we can still block up most of the threads and get bad performance so meter size our pollock heads small we can reason about bulkhead sizes by looking at the peak load when our system is healthy so let’s assume we have 40 requests per second to service and these requests are handled at 0.1 second so this would be a peak load when calling service we have this scenario a suitable bulkhead size would be to multiply these multiply the for two requests per second with the response time of 0.1 seconds and we lead us to a bulking size of four so that would work if we would had a constant load.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 394px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/c5efcdf7a551ced1e170e27276723bea/cc097/18.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 45.56962025316456%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAABJ0AAASdAHeZh94AAAB+0lEQVQoz22R3UuTYRiH37+gg+39fjc3XFNbHYiMV+dyY8OPRXOZomga5Oso54RZzq0Pp2V+JQ3MVpqLoIPIjiIp6IsOOquD/qUr9haxxIMLHp7nvn/c1/0IulunHsOtoxoqsibj8rhY2S+w936L5x/LZJcsugIJAoHTeH0efE0+Sk9u/Hn/VGamZCEcDXS4VDyNHswOEzNksv32Ltvv7rH/7QHFnSxT0TzxaDdBs43Osx1svL7Fo8MVnn3dJF/OIEiKjKIpOFQZv6aQ854k2NFOc6AZURaJpkKkJnu5YPVixttwyA5UQ7EtFF0hfjFMyupjIN1HqCeIML8+zfLjeVarRUbTwxRiTYTMM/hPtdDU4idbslir3mbjxSJj14aoDWA0GP+MREnC4XTaSLKEsPd5k6cf1jn4WWFuLcfcgo6VTtCfGuJcMsHO4X1e/ajw5tcui5XrOCWxLlCzz4bnLw06wlguRXpplMzqBImRGD0jswRaW5E1yVZKTnYzURjkcnGQ+EAYWVU4uvd6BFmV7aLavlSXm87+K/QkeglHOvE2ekmNJ5jKj5NemCB+PkKtvtaoubRjEf6/UBHFE7ZKsD1IJNZF+WCZ6peHvPy+Q35rBqcoork1+1OOQ1B1lXpqwTVVURHRDI2ry5e4uZvhTnWW4emkHWg368fzG2LbNgJEfQIfAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;sixteen&quot;
        title=&quot;sixteen&quot;
        src=&quot;/JPerformance/static/c5efcdf7a551ced1e170e27276723bea/cc097/18.png&quot;
        srcset=&quot;/JPerformance/static/c5efcdf7a551ced1e170e27276723bea/c26ae/18.png 158w,
/JPerformance/static/c5efcdf7a551ced1e170e27276723bea/6bdcf/18.png 315w,
/JPerformance/static/c5efcdf7a551ced1e170e27276723bea/cc097/18.png 394w&quot;
        sizes=&quot;(max-width: 394px) 100vw, 394px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;When using thread pool handovers if we have a fixed number of threads and we don’t NQ requests then we get an included bulkhead if we try to call the service when water they have three outstanding service calls then we will fail immediately with an error so this is great we get generic timeouts and bulkheads with the same construct a straightforward way to implement thread pool handovers is to use a standard java thread pool executors here we neutralize it with three three threads the first two threes or the number of threads and we use a synchronous queue now this is important because if you don’t specify the queue to use request will use an unbounded you assume Chris queue will prevent requests from being and queued and we will instead react executions when all the threads are used and when we want to protect our get offers call using this thread pool handover we submit the call to the executor we will get a future in the return wait for this future with our desired timeout in this case one second if we get a rejected execution exception when submitting our job it means that we already have three outstanding calls.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 423px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/f575a15047835427430c869e5b3ffb26/f687d/20.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 51.89873417721519%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABJ0AAASdAHeZh94AAABpklEQVQoz22SaY6jMBCFOUUIAYclrAbb2GAD3eme+5/qjaoSpIk0Pz5VyeBXy3NUNRXUrLB/7cziHfweMIcDnbZo5QA5dzDrhMlJrF+WsX6G31Zoq1HVFUiHiG7ihizP0PQN+rFH3dWYzIRRSTzaCm3foGgE8kZAPFLkTYa8zXB/CBYQRYZrekWSJUzUyQ7hCC8RPUKqkePsDFcf1IhH2yDJbkjSBFfilrzzlxA1dRLRISXDNEAqiXZoOR+URFmX6MoUshYQefoSEK9O4jTGeffsjgXPg/gWo2pKSGOh3AY1rzCzwe/zgHcGPqxwq8MaVhhrYJzBdmw8DU1XPAouEJ3KVV3CLrRsh0nVMDKHWwb4b49ed9DrhP1ngw0aZtF4/nlygfSesgcUeYenIJniNw8XLEyYoL3C8m1fQk8PtxmYoOB2A7MoLj6MPUQhPnYZncuk3dEIzltoL6GDhNs17KE4LmHB4hf0sud/CXoV9/L+YQx3SO3Sh27o2JBWtkwnW/RTz2aNWr5fgWQhNm4a+N7HsznnJ/VLcnkTv7n8FzKQoJzE/uUvrSofcvy01EsAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;ten&quot;
        title=&quot;ten&quot;
        src=&quot;/JPerformance/static/f575a15047835427430c869e5b3ffb26/f687d/20.png&quot;
        srcset=&quot;/JPerformance/static/f575a15047835427430c869e5b3ffb26/c26ae/20.png 158w,
/JPerformance/static/f575a15047835427430c869e5b3ffb26/6bdcf/20.png 315w,
/JPerformance/static/f575a15047835427430c869e5b3ffb26/f687d/20.png 423w&quot;
        sizes=&quot;(max-width: 423px) 100vw, 423px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;&lt;/h3&gt;
&lt;h3&gt;Monitoring and troubleshooting&lt;/h3&gt;
&lt;p&gt;We probably need to throw in some monitoring here to be able to get a better understanding of our system but what should we monitor yeah of course obvious stuff like heaps , CPU utilization, but what is specific for a microservices architecture , we discovered that a great place to introduce monitoring is to monitor the service calls we have a lot of services to get a good understanding of them we can monitor how they are called this our integration points these are the places were integrating the system with with itself it’s also a good place to detect configuration problems if we protect all our service course with these stability patterns so we need to monitor that we have configured these patterns correctly a crucial thing to measure is the timeout rate the rate at which calls to service or timing out that’s a good problem detector and it is also a good place to validate.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 411px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/b397e1a97c84d164cb7de0d11a5ddb29/2a432/21.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 34.810126582278485%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAABJ0AAASdAHeZh94AAABEklEQVQoz32RaW6DMBBGfYgkEHYoSoA2C2ULiyFFJGmk3v86XzWjUjmp1B9PHuzHeDwj9scd+nOP4lSirEvkVY6iKrC21jBs4xfd1HFI95CDRNPV7BFVU+H4fkDd1kizFMJ2LSS7hIleI2yTLaIk+pOQvr0Xjx1yyYvf4od4E28gSF5oC6zWK0YzNIYSzEnVdakvGdVXY0El37/u6D8GNLKFHDp0fQd5lsjLjCXTNngtqhyX24RhHNDKBsWpYI+wXIsvFKZjIggDOL4D27MZOnR+YrU62g9CH37ow/Vd/oegVsyOmDdJfkjoO6DL1F5STJXSgJ6ZPUGTun5ekZUZuqHDeBn5KdNt4gFQArWP/0EVfgN/EceixBMUSgAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Eighteen&quot;
        title=&quot;Eighteen&quot;
        src=&quot;/JPerformance/static/b397e1a97c84d164cb7de0d11a5ddb29/2a432/21.png&quot;
        srcset=&quot;/JPerformance/static/b397e1a97c84d164cb7de0d11a5ddb29/c26ae/21.png 158w,
/JPerformance/static/b397e1a97c84d164cb7de0d11a5ddb29/6bdcf/21.png 315w,
/JPerformance/static/b397e1a97c84d164cb7de0d11a5ddb29/2a432/21.png 411w&quot;
        sizes=&quot;(max-width: 411px) 100vw, 411px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The developers over at Netflix has made some awesome stuff for example , hystrix implements these patterns it implements circuit breakers red pool handovers bulkheads it’s actually quite great.&lt;/p&gt;
&lt;p&gt;Well maybe in 2022 some Netflix libraries are in maintenance mode now, but there are another options such as some pivotal’s libraries and another frameworks such as Micronaut.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Java Memory Model]]></title><description><![CDATA[It is important to understand the Java memory model if you want to design efficiently low latency systems. The Internal Java Memory Model…]]></description><link>https://github.com/BrahianVT/java-memory-model/</link><guid isPermaLink="false">https://github.com/BrahianVT/java-memory-model/</guid><pubDate>Wed, 14 Jul 2021 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;It is important to understand the Java memory model if you want to design efficiently low latency systems.&lt;/p&gt;
&lt;h2&gt;The Internal Java Memory Model&lt;/h2&gt;
&lt;p&gt;The Java memory model used internally in the JVM divides memory between thread stacks and the heap. Each thread running
in the java virtual machine has its own thread stack. The thread stack contains all local variables for each method being
executed . A thread can only access it’s own thread stack, all the local variables of primitive types are stored on the
thread stack.&lt;/p&gt;
&lt;p&gt;The heap contains all objects created in your Java application, regardless of what thread created the object.&lt;/p&gt;
&lt;p&gt;An object may contain methods and these methods may contain local variables. These local variables are also stored on the thread
stack, even if the object is store on the heap, the object’s member variables are stored on the heap along with the object itself.
The static class variables are also stored on the heap along with the class definition.&lt;/p&gt;
&lt;p&gt;Objects on the heap can be accessed by all threads that jave a reference to the object, if two threads access to an object at the
same time, they will both have their own copy of the local variables.
&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 486px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/73a0393e9246be62b1885c1123ae4af8/4ee7f/jmm.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 89.24050632911393%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAAA7EAAAOxAGVKw4bAAADrklEQVQ4y22UaW8aZxSF+flRVSlSmzpplQQbMxgDs7LDwLAMi2FW1sCAiUkiRakTqU1ahVj2U4Gx5UR9paNz79XR0Xvuhxu6ub7merPhZvMNNt92/B2+fuP6Qc3maq+9utV/vdNsuLm5IfR5uWSeFJgqMSZSlFdKjKks7LCrFYGFdMpMOWGiCoykYyaKwFiO7niqxphqJwSJGJtPnwh9ngXYpTD+WqNsPudUe4xcfEIk8YhK5xD3tYJdOsLqCHgXKmn9KcnMY1L5XzhO/UTLP8FdKbjSCzYfLreGC+zKEd1ApDM+pWpHMEdxrIWEc67gv8viVqNYZzE68xSt4QmGc0xnmsBeyngrFf9tFk8Js/nzI6Ev8wW94kuk6gGpzDPEzO+kK2HcII+3yONcqPhGjFb9kGTpCXL+BUohTKEuMDzX8ZeFW82d4TayW40weJfFG7cYjCy84RmdbgN/3MHaxqlEca043jqH47fxRj3aZwbdbh1v2sBaSfjq4V3kAKcawV1rOEMTb9DH9bv0rDbezlDeRXb6cZxVFn/YZzRxsew2jttnMGthrcTvDW39iPYsiemmaDoiLU+iP83gzHM4a21n2O8KmJNTGnaCppuiPZCwZxncILP7zA87DCNVDpDyB8iFp2jVP3AWGvZcwbnQ8A2Bdv2IZOlXpNwBYv4Z2dpLnHkaJ9BwLx4Y7iIbEfz3BUaBwySYMHw1wPYdpucDrDcaTlXAcU4ZvC8zDgZMlxP6fg936DBeWfTWMt595PmCQS6Ma0Xpm4f09rBaEex2ZDcf5Q4ZVo5wz46xzSOcVgS3E8XbY2CdMBbDfL3cRl4E9GMpqmKJWqpAXSrRkG9rI1WglipiKjp1sYSRLNxqxOIORjJPOaZRjufwhVM2Hy8J/Ru8opAsEzXfkaifI+tdMtUepc4YwViS0D3Uskn1bECiNiNeC5CKJvl6j7Q54edIlUeRKg1B5uryA6F/ghl6skTSXCPXA9L6GYVan0LDJWUESLpHVu9QbthIxgSxNiNd7lCs9UkbHnJzRaKxwow9MCymdE467xFbF+jdIU17StNfEq+vUJtTql2f3niFZC5JmSv0tofpTCn15iTMt4i9D7Ti2q3hl2CGKciktTZZpUFW1MlJ+o6zSpOsZJAVy+S2vVzfa/a9VCGnmgixEo3nEa62O/x88Zq1IvMmrbLWVNZpbQ+VN5qy4/uZ9lCj3muMp7/RPwxz9fdfhLZHcXtkb3lf3+PH/vp/NXdve2D/A7HquE5H9T4NAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Internal Memory&quot;
        title=&quot;Internal Memory&quot;
        src=&quot;/JPerformance/static/73a0393e9246be62b1885c1123ae4af8/4ee7f/jmm.png&quot;
        srcset=&quot;/JPerformance/static/73a0393e9246be62b1885c1123ae4af8/c26ae/jmm.png 158w,
/JPerformance/static/73a0393e9246be62b1885c1123ae4af8/6bdcf/jmm.png 315w,
/JPerformance/static/73a0393e9246be62b1885c1123ae4af8/4ee7f/jmm.png 486w&quot;
        sizes=&quot;(max-width: 486px) 100vw, 486px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;Hadware Memory Architecture&lt;/h2&gt;
&lt;p&gt;Modern hardware memory architecture is somewhat different from the internal java memory model. It’s important to understand the hardware memory architecture too at least in a high level.&lt;/p&gt;
&lt;p&gt;A modern PC has often 2 or more CPUs, usually the CPU’s have multiple cores too, so it’s possible to have more than one thread running simultaneously. Each CPU contains a set of registers which are essentially in-CPU memory. The CPU can perform operations much faster on these registers that it can perform on variables in main memory.&lt;/p&gt;
&lt;p&gt;Modern CPUs have a cache memory layer of some size, the CPU cache is memory is somewhere in between the speed of the internal registers and the main memory. All CPUs can access the main memory, the main memory is typically much bigger than the cache memories.&lt;/p&gt;
&lt;p&gt;When a CPU needs to access main memory it will read part of main memory into its CPU cache. It also read part of the cache into its internal
registers and then perform operations. When the CPU needs to write the result back to main memory it will flush the value back to main memory.
&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 452px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/526af1d03f57b6fc3d8b42a7aa800f20/fcb94/jmm2.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 87.9746835443038%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAAA7EAAAOxAGVKw4bAAADhUlEQVQ4y42Ua08bVxCG/f9/QaVUVZUWUKtAqqiEEBzAxsbY2PgKBl/2fr/v2l5jbHiqXQLhS9Ue6dGeOXrn1Zw5qyk8PT2x2WxYr9es15uch3z/Eq/fsHk9e9V8z808slVYLpdYlkUYBvi+R+D7JHFEFIavcRAEz/h+fhYGPrMkJspyPC/PtW2b++WSwmJ5T+IaPOlt1nqfldpBbhXxbs95NK9Zy03Wacxm5rJWr9gYA1KxhdQsEk0abIw+j0afyLNYpEsK6f0DoSGAWAa7A1oDtfYX0aAITgcmx9yHFitXArkCTpcn6Ry5usdiVAK7DWIF35BIl6uswhWJJaINLqiclqiflbisVrislGnU6si9C1aRxYOvMO40KBWPuKye0aqdUy+f0qxf4oyuCE2J7LaF+XLFzBIYt6p8+Vrm6OsxW9sf+H3rTz4fnnLTqPAQmax9mU79gv2DbxwcHLG9s8v29gcOi2cogyaRKZIVV0jTFNex8QyZxLVQJrfIkztMTSF2TRxVYDGf5Y/gqCKxazEdDtAlAVtXiW0d31DwXJfMq3C/TJE0m7aQUG5NOKj0OGmO2D9tU+0pXI5DbD9Bc2LaQkyxdsNhpc9pa8LfJ1fUhyZdMUbRs1f+biiqJj0x4qIz5uffdnn3fpdfdz7RvjO5GntYboRqhVzLMSe1Hj/9ssO79x/Z+XhEf+rSFwMk1fxhKKkWrZFLX/CoXE0oXY6otAUGUkBjaOH4Ebod0ho5dCcu5eYd5eaYWk9mIAa0Rw6KZrLMDBeLBY7jEEYJfhijagaSoiFIMn4Q4fkhYRjluH6I6wWIsoqsaDlZXhQnuUfmVVimaV7uQPAYyj7NG4XOyOBG8hkbCXdqxNiYMdJiJsYsp3mt0JtYDKYOQ8nPtXmFL48ylQ0604ChEjJUIkb6jG/VDlu7h3wpXbG9e8je5zP++HTM3n6Z9tjmVk24kZ/1XcFHkPUfPZxIOs2RR1/w6U49eoJPc2hw3pVo3OhUOyIXfSWPs9627qxc05m4uT7r7athmi7yvgmah6A6r4i6h2wESC9fw0fOMAMEzUXUPFQ7QrVDdCdGN0wyr8J8Psc0TRbzJJ8ys+SZbP9vzGcJjm3R73bodbtc93soivr8Y2fjS1EUdMNA1/X/RNN1DMNEEATqF3UqZ1Xq9TqSJLNarShkQ3HzZkj+HzLt4+Mjb9dL/A/yFCPcYl0jgwAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Internal Memory&quot;
        title=&quot;Internal Memory&quot;
        src=&quot;/JPerformance/static/526af1d03f57b6fc3d8b42a7aa800f20/fcb94/jmm2.png&quot;
        srcset=&quot;/JPerformance/static/526af1d03f57b6fc3d8b42a7aa800f20/c26ae/jmm2.png 158w,
/JPerformance/static/526af1d03f57b6fc3d8b42a7aa800f20/6bdcf/jmm2.png 315w,
/JPerformance/static/526af1d03f57b6fc3d8b42a7aa800f20/fcb94/jmm2.png 452w&quot;
        sizes=&quot;(max-width: 452px) 100vw, 452px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;Mapping between the Java Memory Model and the Hardware Memory Model&lt;/h2&gt;
&lt;p&gt;The hardware memory architecture does not distinguish between thread stacks and the heap. On the hardware, both the thread stack and the heap  are located in main memory. Parts of the thread stacks and the heap may sometimes be present in the CPU caches and in internal CPU  registers, this illustrated in the image:
&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/79079c617bc6e7411ed02987b993d0dd/98314/jmm3.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 46.835443037974684%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAB+0lEQVQoz42SSU8aAQCF5/+f2lPTtIfWVFKpMVFQrGiEMsMwSxEXBFmcGWaFWaEgFqhfU0169iVfvuTdXvIEXpHVes08i1lnHtPA4CEc8TgNWU4jVqlL5t3zO3GZxWMEXxFx9Cpes4bdqODIFbwLEUerEuh1WK1Y/3li7g9IOzX6cgm3WebRbbP07wivK/TqR0Q3VaajW4R2LU9Rfkf+9C2yuoWubpM/fUNRfo9eyZH6Y2bzOWb3mpamUKv+oCGKJM6AzDNQpDpSTaSpKkT2AKFf3UNtbCFLn7mWctxKX5HET+jqF27Od4m9gEk4oWe4tLo2Z1IT7cbECqa44S/kix7n9UtaPQ/TixD0/TKHRY2TkkapoFAqKpRLOkdFjcZ+mci1CaOIgeXzs+NQOJEQLwaYfoYzmSE1+8+d3nExnBChdlxnS/TIN3w+lNp8PO6wI/tsywHfD0Vm4+Bl8sjF9FM6Q5ehHWJ6MZaf0LfG9MyAezfG9iYInb19lJ0DtG//KKDlD9B3C0i5PdTcDpvFgsXDgquuSWuYcDmMOZHaHNeuOKq2OFd7XBkpl8aUOzNAWHouS9ti6YxebFs8OiMWlkFiGvD0xHq9xgsm2H6E7Yc4QfQfN4gxbJ9u3+TeHCG85oebzYYsTUmThDRNXvxMzDRLCXyPzm0bx3H4C7JVgms+bG5AAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Internal Memory&quot;
        title=&quot;Internal Memory&quot;
        src=&quot;/JPerformance/static/79079c617bc6e7411ed02987b993d0dd/f058b/jmm3.png&quot;
        srcset=&quot;/JPerformance/static/79079c617bc6e7411ed02987b993d0dd/c26ae/jmm3.png 158w,
/JPerformance/static/79079c617bc6e7411ed02987b993d0dd/6bdcf/jmm3.png 315w,
/JPerformance/static/79079c617bc6e7411ed02987b993d0dd/f058b/jmm3.png 630w,
/JPerformance/static/79079c617bc6e7411ed02987b993d0dd/98314/jmm3.png 817w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;When the objects and variables are stored in  different memory areas on the hardware, certain problems may occur. The two main problems are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Visibility of thread updates (writes) to shared variables&lt;/li&gt;
&lt;li&gt;Race conditions when reading, checking and writing shared variables.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Shared Object Visibility&lt;/h2&gt;
&lt;p&gt;If two or more threads share objects is mandatory to use either volatile declarations or synchronization. When a shared object is initially stored in main memory, a thread running on the CPU reads the object into its CPU cache. And if the CPU cache doesn’t flush the changes back to main memory, the changed version of the shared object is not visible to threads running on other CPUs so each thread may end up with its own copy of the shared object, each copy setting in a different CPU cache.&lt;/p&gt;
&lt;p&gt;To solve this problem use the keyword &lt;strong&gt;volatile&lt;/strong&gt; and always the variables will be written back to main memory.
&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 520px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/09c2d84db7cd16274aee61b0421ff75e/69902/jmm4.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 75.31645569620254%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAC8ElEQVQ4y42UWXPbNhRG+f//RadpOk48cR1LSRNvo9iSvEjWYnnRQpOiSIAEQVKidjme0yHlTNP2pQ9n7ndxP1zgPgDGfD4nnWUsmM4WzObLPGZ5Op2RpilpOn0l3a691qfzLdt8zmw2w4gizSqRLPSIeTgi9W0W2s3z5XTMcrVmuVxuyfR0nNcyz1Q5TINhrrMeOgwxYq1gWAH/hmWvxKD0DkZX4FTYaJvNC2w26y0v8KztrT9o4NeKeNcFkDWwy2jlY4y1T9K7on1Z5qFWyem1arj3NVbKYv38wmq12vL8nbUeYreq3F6d81iv5vRadeLeFbESGGnkIzpVjr6e8OVTkTe/vGF/b59G5Rvr8Inl5pnVcpmT6Y22aFW/cfjlkI97e7z99S2Fg894nQsS5WGEoUYIhZQK07Sxhi5KxUgZMZnM+Z7fcJ2T6WzNExrX8+n2nvCkQqkIIQKUUhjSV7TtlONqh51CiXeFM/aPKlzed7h/esD1uwTaRccSz+/TdwY0zQH7hxV2DkrsfDylVDdpWRM84WMIP6BhxtTuHH7/45jdwjlfyxeULvc5uy5y0SxiOh36T20qtc9ct09o96sclW/47cMxHz6dU+/6NPoaT0iMQCmEShDhmKEIeRw4jKTG1wkqUnQHbaQaYloPyMBmkqZ4QYwXJAxskSPUOO/h+342coDpxphuROvRodN36Y80T96EB9uh3jmh3jnl3qzyOGxgegmWGNMdKm7uLB4tH9OLGbjx9obZ3LWepm3F3Npjbq0kpznQvC+ecnB0xG6xyG6hwPuDIn+etWmZUe7v2GPaVpLr667Gcb2soaTWVTT6PxPmsXrrcHknqLZdyq0R502by86I5iDMD/zhb/ZDat0AZ+RhZHPHyQQdJUTxP0nGE+JknMcfhDoiUCF+EKJffdnerIcQAsNxHKSUSCGQ8l+ILeK15nkuZ9/OOD48pHxe/nuPEPhSYts2xnr90+P/H2S/U/arLBaL/9Sy5/kXkglEYBr2Hu0AAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Internal Memory&quot;
        title=&quot;Internal Memory&quot;
        src=&quot;/JPerformance/static/09c2d84db7cd16274aee61b0421ff75e/69902/jmm4.png&quot;
        srcset=&quot;/JPerformance/static/09c2d84db7cd16274aee61b0421ff75e/c26ae/jmm4.png 158w,
/JPerformance/static/09c2d84db7cd16274aee61b0421ff75e/6bdcf/jmm4.png 315w,
/JPerformance/static/09c2d84db7cd16274aee61b0421ff75e/69902/jmm4.png 520w&quot;
        sizes=&quot;(max-width: 520px) 100vw, 520px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;Race Conditions&lt;/h2&gt;
&lt;p&gt;If two or more threads updates variables in  a shared object a race condition may occur. For example it two theads read a varible let’s suppose it is 1 and both threads increase by 1 so the final result will be 3, but if there is a race condition the final result will be 2 because each thread will try to write to main memory their own result.
&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 542px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/03deb5635c5cdb901e055ac3c1fb9e34/c0388/jmm5.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 68.9873417721519%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAC0klEQVQ4y3WS6W7bRhRG9f4PEaBAixZIE6SxE1u2FTvaZS2hRIlaSImUTFHiMlwkand9ClJu0xToj4M7c+ebg8sls16vCVcxUbxlFW/Z7g9pjdZbotWaKIp+JOml5xs2uz3xdpdmE0fiyvhByG4xYj/vEc9kTLlM/NRN97tgwf5wZL/fnTmc2Cc9s8ve6rPs1/C0JgdLYbdQEcInE0Qrno0qzKv8qZeYlt7zMq3ArMTBVjk+v3A8HFIOzy+cbBWmJbAaLOsXhN3b9O5Jr+IHEZlVFOKOmlx8+sLn6xyXn274cHFLrVxjs9Q4nJ6/T3g8sbPHFL8W+PAxy/V1jo8XWT7fFPBUiTDwyYRhyGqmMFE6DKQGlfw9itTEGsnsxJzDMRHuU9K1mGMOO2hdiXrxAemxiq50WD31CYKATBD4qGZAV7OoSSNaikGrp6MYNk+2II4j4jhmHa/ZbCJmtkdPX1LvqDx2NJrdCX3dSR2+EGQCX9AeCx7qKm9+veSnt7f8fn1PvpmjIeeRRwV0U2GkSzQ6OVpKnnInz8/vsrz57Ypf3t9RVRZImosvvLNwYLgohqDybcSXskxTmdBUGsiDJt3hI65voU4UBlqLoS7THnVpKlNypTbV9pjBLKBvOIhEKITAFSGOCJmaC/TZnPnCxQ932MKjrRToazV6agXD6uMFGzw/xlp6qJMppuXgighXBHieSyYZs6056WNLalI9OpMEn9tSnZv8BVf3f3BXvCRbyFLpGMi6oK25aV6enF9ZW7XPwmRMSXOQdZ+eEdA1/H+4Kba5r424Kytkiz2uHtp8bYzoTESa777mk7WUCN1XoW66aE8u4x/wmC5CDMvHWARME5YhprvGdNbpmfaaS2riSIW2bSO88xf6L0n/b5K9s7RoNRpUyyV6vV76I/87u1wuyaxWKxzXxfO8/8V9rY7jMNbGDAdDDGOK54nvZ65L4voLyKX41B/B/jwAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Internal Memory&quot;
        title=&quot;Internal Memory&quot;
        src=&quot;/JPerformance/static/03deb5635c5cdb901e055ac3c1fb9e34/c0388/jmm5.png&quot;
        srcset=&quot;/JPerformance/static/03deb5635c5cdb901e055ac3c1fb9e34/c26ae/jmm5.png 158w,
/JPerformance/static/03deb5635c5cdb901e055ac3c1fb9e34/6bdcf/jmm5.png 315w,
/JPerformance/static/03deb5635c5cdb901e055ac3c1fb9e34/c0388/jmm5.png 542w&quot;
        sizes=&quot;(max-width: 542px) 100vw, 542px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To avoid this use a Java &lt;strong&gt;synchrnized block&lt;/strong&gt; so it guarantees that only one thread can enter a critical section at a given time.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[The Z Garbage Collector]]></title><description><![CDATA[The Z Garbage Collector (ZGC) is a scalable low latency garbage collector. ZGC performs all expensive work concurrently, without stopping…]]></description><link>https://github.com/BrahianVT/z-garbage-collector/</link><guid isPermaLink="false">https://github.com/BrahianVT/z-garbage-collector/</guid><pubDate>Fri, 09 Jul 2021 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;The Z Garbage Collector (ZGC) is a scalable low latency garbage collector. ZGC performs all expensive work concurrently, without stopping
the execution of application threads for more than 10ms, which makes is suitable for applications which require low latency and/or use
a very large heap (multi-terabytes).&lt;/p&gt;
&lt;p&gt;The Z Garbage Collector is available as an experimental feature, and is enabled with the command-line options &lt;strong&gt;-XX:UnlockExperimentalVMOptions&lt;/strong&gt;
and &lt;strong&gt;-XX:+UseZGC&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;Setting the Heap Size&lt;/h2&gt;
&lt;p&gt;The most important tuning option for ZGC is setting the max heap size (&lt;strong&gt;-Xmx&lt;/strong&gt;). Since ZGC is a concurret collector a max heap size must be
selected such that, 1) the heap can be accommodate the live-set of your application, and 2) there is enough headroom in the heap to allow allocations to be serviced while the GC is running. How much headroom is needed very much depends on the allocation rate and the live-set size of
the application. In general, the more memory you give to ZGC the better. But at the same time, wasting memory is undesirable, so it’s all about
finding a balance between memory usage and how often the GC needs to run.&lt;/p&gt;
&lt;h2&gt;Setting Number of Concurrent GC Threads&lt;/h2&gt;
&lt;p&gt;The second tuning option one might want to look at is setting the number of concurrent GC threads &lt;strong&gt;-XX:ConcGCThreads&lt;/strong&gt;. ZGC has heuristics to automatically select this number. This heuristic usually works well but depending on the characteristics to automatically select this number. This
heuristic usually works well but depending on the characteristics of the application this might need to be adjusted. This option essentially dictates how much CPU-time the GC should be given. Give it too much and the GC will steal too much CPU-time from the application. Give it too little, and the application might allocate garbage faster than the GC can collect it.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Garbage-First Garbage Collector Tuning]]></title><description><![CDATA[General Recommendations for G1 The general recommendations is to use G1 with its defaults settings, eventually giving it a different pause…]]></description><link>https://github.com/BrahianVT/garbage-First-Collector-tuning/</link><guid isPermaLink="false">https://github.com/BrahianVT/garbage-First-Collector-tuning/</guid><pubDate>Mon, 05 Jul 2021 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;General Recommendations for G1&lt;/h2&gt;
&lt;p&gt;The general recommendations is to use G1 with its defaults settings, eventually giving it a different pause-time goal and setting a maximum Java heap size by using &lt;strong&gt;-Xmx&lt;/strong&gt; if desired.&lt;/p&gt;
&lt;p&gt;G1 defaults have been balanced differently than either of the other collectors. G1’s goals in the default configuration are neither maximum throughput nor lowest latency, but to provide relatively small, uniform pauses at high throughput. However, G1’s mechanisms to incrementally reclaim space in the heap and the pause-time control incur some overhead in both the application threads and in the
space-reclamation efficiency.&lt;/p&gt;
&lt;p&gt;If you prefer high throughput, then relax the pause-time goal by using &lt;strong&gt;-XX:MaxGCPauseMillis&lt;/strong&gt; or provide a larger heap. If latency is the main requirement, then modify the pause-time target. Avoid limiting the young generation size to particular values by using options like &lt;strong&gt;-Xmn&lt;/strong&gt; and &lt;strong&gt;-XX:NewRatio&lt;/strong&gt; and others because the young generation size is the main means for G1 to allow it to meet the pause-time. Setting the young generation size to a single value overrides and practically disables pause-time control.&lt;/p&gt;
&lt;h2&gt;Moving to G1 from Other Collectors&lt;/h2&gt;
&lt;p&gt;Generally, when moving to G1 from other collectors, particularly the Concurrent Mask Sweep collector, start by removing all options that affect garbage collection, and only set the pause-time goal and overall heap size by using &lt;strong&gt;-Xmx&lt;/strong&gt; and optionally &lt;strong&gt;-XMs&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;Improving G1 Performace&lt;/h2&gt;
&lt;p&gt;G1 is designed to provide good overall performance without the need to specify additional options. However, there are cases when the default heuristics or default configurations for them provide suboptimal results. For diagnosis purposes, G1 provides comprehensive logging. A good start is to use the &lt;strong&gt;-Xlog:gc*=debug&lt;/strong&gt; option and then refine the output from that if necessary.&lt;/p&gt;
&lt;h2&gt;Observing Full Garbage Collections&lt;/h2&gt;
&lt;p&gt;A full heap garbage collection is time consuming. Full GCs caused by too high heap occupancy in the old generation can be detected by finding the words Pause Full in the log. Full GCs are typically preceded by garbage collections that encounter an evacuation failure indicated by &lt;strong&gt;to-space-exhausted&lt;/strong&gt; tags.&lt;/p&gt;
&lt;p&gt;G1 gives you several options to handle this situation better:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You can determine the number of regions occupied by humongous objects on the Java heap using the the &lt;strong&gt;gc+heap=info&lt;/strong&gt; logging Y in the lines “Humongous regions : X -&gt; Y” give you the amount of regions occupied by humongous objects. If this number is high compared to the number of old regions, the best option is to try to decrease the objects by using &lt;strong&gt;-XX:G1HeapRegionsSize&lt;/strong&gt; .&lt;/li&gt;
&lt;li&gt;Increase the size of the Java heap. It typically increases the amount of time marking has to complete.&lt;/li&gt;
&lt;li&gt;Increase the number of concurrent marking threads by setting &lt;strong&gt;-XX:ConcGCThreads&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Force G1 to start marking earlier. G1 automatically determines the Initiating Heap Occupancy Percent threshold based on earlier application behavior. There are two options: Lower the target occupancy for when to start space-reclamation by increasing the buffer used in an adaptive IHOP calculation by modifying &lt;strong&gt;-XX:G1ReservePercent&lt;/strong&gt; ; or, disable the adaptive calculation of the IHOP by setting it manually using -XX:-G1UseAdaptiveIHOP and &lt;strong&gt;-XX:InitiatingHeapOccupancyPercent&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Humongous Object Fragmentation&lt;/h2&gt;
&lt;p&gt;A Full GC could occur before all Java heap memory has been exhausted due to the necessity of finding a contiguous set of regions for them. Potencial options in this case are increasing the heap region size by using the option &lt;strong&gt;XX:G1HeapRegionSize&lt;/strong&gt; to decrease the number of humongous objects, or increasing size of the heap.&lt;/p&gt;
&lt;h2&gt;Tuning for Latency&lt;/h2&gt;
&lt;p&gt;Improve G1 behavior in case of common latency problems that is, if the pause-time is too high.&lt;/p&gt;
&lt;h3&gt;Unusual System or Real-Time Usage&lt;/h3&gt;
&lt;p&gt;For every garbage collection pause, the &lt;strong&gt;gc+cpu=info&lt;/strong&gt; log output contains a line including information from the operating system with a breakdown about where during the pause-time has been spent. An example for such output is &lt;strong&gt;User=0.19s Sys=0.00s Real=0.01s&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;User time is time spent in VM code, system time is the time spent in the operating system, and real time is the amount of absolute time passed during the pause.If the system time is relatively high, then most often the environment is the cause.&lt;/p&gt;
&lt;p&gt;Common known issues for high system time are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The VM allocating or giving back memory from the operating system memory from the operating system memory may cause unnecessary delays. Avoid the delays by setting minimum and maximum heap sizes to the same value using the options &lt;strong&gt;-Xms&lt;/strong&gt; and _&lt;strong&gt;-Xmx&lt;/strong&gt;, and pre-touching all memory using &lt;strong&gt;-XX:AlwaysPreTouch&lt;/strong&gt; to move this work to the VM startup phase.&lt;/li&gt;
&lt;li&gt;In Linux, coalescing of small pages into huge pages by the Transparent Huge Pages (THP) feature tends to stall random processes, not just during a pause. Because the VM allocates and maintains a lot of memory, there is a higher than usual risk that the VM will be the process that stalls for a long time.&lt;/li&gt;
&lt;li&gt;Writing the log output may stall for some time because of some background task intermittently taking up all I/O bandwidth for the hard disk the log is written to.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Reference Object Processing Takes Too Long&lt;/h2&gt;
&lt;p&gt;Information about the time taken for processing of Reference Objects is shown in the Reference Processing phase. Here the G1 updates the referents of Reference Objects according to the requirements of  the particular type of Reference Object. By default, G1 tries to parallelize the sub-phases of the Reference Processing using the following heuristic: for every &lt;strong&gt;-XX:ReferencePerThread&lt;/strong&gt; reference Objects start a single thread, bounded by the value in &lt;strong&gt;-XX:ParallelGCThreads&lt;/strong&gt;. This heuristic can be disabled by setting &lt;strong&gt;-XX:ReferencePerThread&lt;/strong&gt; to 0 to use all available threads by default, or parallelization disabled completely by &lt;strong&gt;-XX:-ParallelRefProcEnabled&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;Young-Only Collections Within the Young-Only Phase Take Too Long&lt;/h2&gt;
&lt;p&gt;The time is proportional to the size of the young generation, the number of live objects within the collection set that  needs to be copied, one tuning is decrease &lt;strong&gt;-XX:G1NewSizePercent&lt;/strong&gt;.
Also decrease the maximum young generation size  by using &lt;strong&gt;XX:G1MaxNewSizePercent&lt;/strong&gt;. This limits the maximum size of the of the young generation and so the number of objects that need to be processed during the pause.&lt;/p&gt;
&lt;h2&gt;Mixed Collections Take Too Long&lt;/h2&gt;
&lt;p&gt;Mixed collections are used to reclaim space in the old generation. The collection set of mixed collections contains young and old generation regions. You can obtain information about how much time evacuation of either young or old generation regions contribute to the pause-time by enabling the &lt;strong&gt;gc+ergo+cset=trace&lt;/strong&gt; log output. Look at the predicted young region time and predicted old region time for young and old generation regions respectively.To reduce the contribution of  the old generation regions to the pause-time, G1 provides the following options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spread the old generation region reclamation across more garbage collection by increasing &lt;strong&gt;-XX:G1MixedGCCountTarget&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Avoid collecting regions that take a proportionally large amount of time to collect by not putting them into the candidate collection set by using &lt;strong&gt;-XX:G1MixedGCLiveThresholdPercent&lt;/strong&gt;, highly occupied regions take a lot of time to collect.&lt;/li&gt;
&lt;li&gt;Stop old generation space reclamation earlier so that G1 won’t collect as many highly occupied regions. In this case, increase &lt;strong&gt;-XX:G1HeapWastePercent&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;High Update RS and Scan RS Times&lt;/h2&gt;
&lt;p&gt;To enable G1 to evacuate single old generation regions, G1 tracks locations of cross-region references, that is references that point from one region to another. The set of cross-region references pointing into a given region is called that region’s remembered set. The remembered sets must be updated when moving the contents of a region. Maintenance of the regions’ remembered sets is mostly concurrent.&lt;/p&gt;
&lt;p&gt;G1 requires complete remembered sets for garbage collection, so the Update RS phase of the garbage collection processes any outstanding remembered set update requests. The Scan RS phase searches for object references in remembered sets, moves region contents, and then updates these object references to the new locations. Depending on the application, these two phases may take a significant amount of time.&lt;/p&gt;
&lt;p&gt;Adjusting the size of the heap regions by using the option &lt;strong&gt;-XX:G1HeapRegionSize&lt;/strong&gt; affects the number of cross-region references and as well as the size of the remembered set. Handling the remembered sets for regions may be significant part of garbage collection work.&lt;/p&gt;
&lt;p&gt;G1 tries to schedule concurrent processing of the remembered set updates so that the Update RS phase takes approximately &lt;strong&gt;-XX:G1RSetUpdatingPauseTimePercent&lt;/strong&gt; percent of the allowed maximum pause time. By decreasing this value, G1 usually performs more remembered set update work concurrently.&lt;/p&gt;
&lt;p&gt;Spurious high Update RS times in combination with the application allocating large objects may be caused by the optimization that tries to reduce concurrent remembered set update work by batching it. If the application that created such a batch happens just before a garbage collection, then the garbage collection must process all this work in the Updated RS times part of the pause. Use &lt;strong&gt;—XX:ReduceInitialCardMarks&lt;/strong&gt; to disable this behavior and potentially avoid these situations.&lt;/p&gt;
&lt;p&gt;Scan RS Time is also determined by the amount of compression that G1 performs to keep remembered set storage size low. The more compact the remembered set is stored in memory, the more time it takes to retrieve the stored values during garbage collection. G1 automatically performs this compression, called remembered set, coarsening, while updating the remembered sets depending on the current size of that region’s remembered set. The highest compression level, retrieving the actual data can be very slow. The option &lt;strong&gt;XX:G1SummarizeRSetStatsPeriod&lt;/strong&gt; in combination with &lt;strong&gt;gc+remset=trace&lt;/strong&gt; level logging shows if this coarsening occurs. If so, then the X in the line “Did &lt;X&gt; coarsenings” in the Before GC Summary section shows a high value. The &lt;strong&gt;-XX:G1RSetRegionEntries&lt;/strong&gt; option could be increased significantly to decrease the amount of these coarsenings.&lt;/p&gt;
&lt;h2&gt;Tuning for Throughput&lt;/h2&gt;
&lt;p&gt;G1’s default policy tries to maintain a balance between throughput and latency; however, there are situations where higher througput is desirable. Apart from decreasing the overall pause-times, the frequency of the pauses could be decreased. The main  idea is to increase the maximum pause time by using &lt;strong&gt;-XX:MaxGCPauseMillis&lt;/strong&gt;. The generation sizing heuristics will automatically adapt the size of young generation, which directly determines the frequency of pauses. If that does not result in expected behavior, particulary during the space-reclamation phase, increasing the minimum young generation size using &lt;strong&gt;-XX:G1NewSizePercent&lt;/strong&gt; will force G1 to do that.&lt;/p&gt;
&lt;p&gt;In some cases, &lt;strong&gt;-XX:G1MaxNewSizePercent&lt;/strong&gt;, the maximum allowed young generation size, may limit throughput by limiting young generation size. In this example combined percentage of Eden regions and survivor regions is close to _&lt;strong&gt;XX:G1MaxNewSizePercent&lt;/strong&gt; percent of the total number of regions. Consider increasing &lt;strong&gt;-XX:G1MaxNewSizePercent&lt;/strong&gt; in this case. Another option to increase throughput is to try to decrease the amount of concurrent work in particular, concurrent remembered set updates often require a lot of CPU resources. Increasing &lt;strong&gt;-XX:G1RSetUpdatingPauseTimePercent&lt;/strong&gt; moves from work concurrent operation into the garbage collection pause. Also the concurrent remembered set updates can be disabled by setting &lt;strong&gt;-XX:-G1UseAdaptiveConcRefinement&lt;/strong&gt; , &lt;strong&gt;-XX:G1ConcRefinamentGreenZone=2G&lt;/strong&gt; , &lt;strong&gt;-XX:G1ConcRefinementThreads = 0&lt;/strong&gt;. This mostly disables this mechanism and moves all remembered set update work into the next garbage collection pause.&lt;/p&gt;
&lt;p&gt;Enabling the use of large pages by using &lt;strong&gt;-XX:+UseLargePages&lt;/strong&gt; may also improve throughput, you can minimize heap resizing work by disabling it, set the options &lt;strong&gt;-Xms&lt;/strong&gt; and &lt;strong&gt;-Xmx&lt;/strong&gt; to the same value, in adition you can use &lt;strong&gt;-XX:+AlwaysPreTouch&lt;/strong&gt; to move the operating system work to back virtual memory with physical memory to VM startup time.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Garbage-First Garbage Collector]]></title><description><![CDATA[Garbage-First Garbage Collector The garbage first (G1) garbage collector is targeted for multiprocessor machines with a large amount of…]]></description><link>https://github.com/BrahianVT/garbage-First-Collector/</link><guid isPermaLink="false">https://github.com/BrahianVT/garbage-First-Collector/</guid><pubDate>Sat, 03 Jul 2021 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;Garbage-First Garbage Collector&lt;/h2&gt;
&lt;p&gt;The garbage first (G1) garbage collector is targeted for multiprocessor machines with a large amount of memory. It attempts to meet garbage collection pause-time goals with high probability while achieving
high throughput, some features include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Heap sizes up to tens of GBs or larger, with more than 50% of the Java heap occupied with live data&lt;/li&gt;
&lt;li&gt;Rates of object allocation and promotion that can vary significantly over time.&lt;/li&gt;
&lt;li&gt;A significant amount of fragmentation in the heap.&lt;/li&gt;
&lt;li&gt;Predictable pause-time target goals that aren’t longer than a few hundred milliseconds&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;G1 replaces the Conncurrent Mark-Sweep (CMS) collector, It is also the default collector. G1 Collector achieves high performance and tries to meet pause-time goals in several ways.&lt;/p&gt;
&lt;h2&gt;Basic Concepts&lt;/h2&gt;
&lt;p&gt;Enable it by providing &lt;strong&gt;-XX:+USeG1GC&lt;/strong&gt; on the command line, it is generational, incremental, parallel, mostly concurrent, stop-the-world and evacuating garbage collector which monitors pause-time goals in each of the stop-the-world pauses. Space-reclamations efforts concentrate on the young generation where it is most efficient to do so, with occasional space-reclamation in the old generation, occasional reclamation in the old generation.&lt;/p&gt;
&lt;p&gt;To keep stop-the-world pauses short for space-reclamation, G1 performs space-reclamation incrementally in steps and in parallel. G1 achieves predictability by tracking information about previous application behavior and garbage collection pauses to build a model of the associated costs. It uses this information to size the work done in the pauses. G1 reclaims space in the most efficient areas first.&lt;/p&gt;
&lt;p&gt;G1 reclaims space by using evacuation: live objects found within selected memory areas to collect are copied into new memory areas, compacting them in the process. After the evacuation, the space previousl occupied by live objects is reused for allocation by the application.&lt;/p&gt;
&lt;p&gt;The Garbage-First collector is not a real-time collector. It tries to meet set pause-time targets with high probability over a longer time.&lt;/p&gt;
&lt;h2&gt;Heap Layout&lt;/h2&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 447px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/efdc1cd961410c569c8297e6bc71fc7f/a2d48/heapLayount.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 67.08860759493672%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAAsTAAALEwEAmpwYAAACUElEQVQoz0WQy09aYRDF+aObLrsz7mybpo19mZqqqYltDKki1BQQISAqT+/9XjPzPbmAcJGFbUw3DWDazWRmTnJ+cybjQxiPRslkPH7403y+2Xq5WR089Ia/zqJRbKejWWqn84O6O2qaa5zCIA1hkAyHzrn7+/uM4jG4cL6XPdvJNnOnnZ/V3PZRYTd3wW1X2Mb2Xvv7SaVHzT70hBZopOAAKoqi6XSa6cXA3Li6k619+qpC0NNZ8f1BZSdrrEHr80/Xzl9t+WHwVscCBZgOIwGacz6bzTKnHd/kibQuTG5ZzCTQMdw3Br+VEDS4za2/zX/4qr2PwR3dpGU+KbRCW3gpxd3dXYYJqZAkIYXkuAEVmeafvcivvZHGGsJYEmiHijP0uSfrp+/2wTklVRzHaZpmLIEfT2qfv5U/7reE5RRYu8/6snLjI0y8BmtdPfYRDaPaRbfFaiyJ0YNS8/k8c30DN3p8/OW0sF8QSmlrW8Xa1dllNXJtGcpXvNLVh3Vd7XsIo1iHSlf3hOGcpbNZptT1FzwpsnEnzON+X7mktLFVfr1DzgLq3RI/bJj8hapHjtlU6IEmsEY/ZgYAY4zgXCNyIu29stYmCRdCG42grNFKSa21EAKRlAIievw2AFhrleB6NCltbBU3toS2VpNSCxO1UN2yWkQ0xiDiymhBVkotyIJrHxonZ5c/alwCIXLOiUjKRyYRLcmolEJExtiCvCJIKZ21QqMdJlKIpd2i/lNXPREBwH/yaniUhbRaI5FzDhGdc6u7aLkhokWQpcUq81+wXJE2MzfXcAAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Heap Layout&quot;
        title=&quot;Heap Layout&quot;
        src=&quot;/JPerformance/static/efdc1cd961410c569c8297e6bc71fc7f/a2d48/heapLayount.png&quot;
        srcset=&quot;/JPerformance/static/efdc1cd961410c569c8297e6bc71fc7f/c26ae/heapLayount.png 158w,
/JPerformance/static/efdc1cd961410c569c8297e6bc71fc7f/6bdcf/heapLayount.png 315w,
/JPerformance/static/efdc1cd961410c569c8297e6bc71fc7f/a2d48/heapLayount.png 447w&quot;
        sizes=&quot;(max-width: 447px) 100vw, 447px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;G1 partitions the heap into a set of equally sized heap regions, each a contiguous range of virtual memory as shown in the image, a region is the unit of memory allocation and memory reclamation. At any given time, each of these regions can be empty, or assigned to a particular generation, young or old. As requests for memory comes in, the manager hands out free regions. The memory manager assigns them to a generation and  then returns them to the application as free space into which it can allocate itself.&lt;/p&gt;
&lt;p&gt;The young generation contains eden regions (red) and survivor regions (red with “S”). These regions provide the same function as the respective contiguous spaces in other collectors, with the difference that in G1 these regions are typically laid out in a noncontiguous pattern in memory. Old generation regions may be humongous (light blue with “H”) for objects that span multiple regions.&lt;/p&gt;
&lt;p&gt;An application always allocates into a young generation, that is, eden regions, with the exception of humongous objects that are directly allocated as belonging to the old generation.&lt;/p&gt;
&lt;h2&gt;Garbage Collection Cycle&lt;/h2&gt;
&lt;p&gt;On a high level, the G1 collector alternates between two phases. The young-only phase contains garbage collections that fill up the currently available memory with objects in the old generation gradually. The space-reclamation phase is where G1 reclaims space in the old generation gradually. The space-reclamation phase  in where G1 reclaims space in the old generation incrementally, in addition to handling the young generation. Then the cycle restarts with a young-only phase.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 474px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/a8b751e2e0b8814b75635db19a65e7b7/5595f/regions.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 72.15189873417721%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB10lEQVQoz31Sy47TMBTN57JHfA1ijdiwRIhZA2IQncJ0mj4zfSRN4sRJ7PgRO7YvStJmqGbEkWVdy+ccH91rT8imNSbD5S48HU9pFKd5ln+epfMT8cNiG+NFmC8SbuJJ7X9CmKC8MMYCgAPw/HVweze7X2x+z1c/pw+zZXBMslcf/LdfjwCutc5Y0wDwybv6y2uq4F94jVK0ZqRmlHEpRJKVN3dBRZlx3bV1PbrKgmm/rbNKaKVNWZGKUG/w6JmAmbo/YAAw9kl1Qe/ggN68odP3adUkKfLcBQAQZSWu5UBslF5t97PFZrnZ/fHXSimAjqQWH+vH772b80bnprU/NggGSrc73baMCyGkkI215xTOuRgVznY988bMXKq8YuPxRQwBJw+rgtRX4nWEf20SozUTkveLccmE4EIw0RVCNFxIrdV0h6OcXsS9X0WovwrG439ACG3b9iweI+UlsX2OoiLHU4ryIoxRnGRhjA5RwoUcBoFweZ7zKAUAGhcs6HpWlNVyu48SdIySfRgHhzDYh5R2HaHblCMyzM67CqRMvk9VH+lFNFrnhxSUuX75At22aY5lo54ruZD9xzZP3/M5yRiLCa3mES8Zk5LJhhd15UdFXQ/jHcV/ARhuIx8FuipuAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Cycles&quot;
        title=&quot;Cycles&quot;
        src=&quot;/JPerformance/static/a8b751e2e0b8814b75635db19a65e7b7/5595f/regions.png&quot;
        srcset=&quot;/JPerformance/static/a8b751e2e0b8814b75635db19a65e7b7/c26ae/regions.png 158w,
/JPerformance/static/a8b751e2e0b8814b75635db19a65e7b7/6bdcf/regions.png 315w,
/JPerformance/static/a8b751e2e0b8814b75635db19a65e7b7/5595f/regions.png 474w&quot;
        sizes=&quot;(max-width: 474px) 100vw, 474px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In the image describes the phases, their pauses and the transition between the phases of the G1 garbage collection in detail:&lt;/p&gt;
&lt;h2&gt;Young-only&lt;/h2&gt;
&lt;p&gt;This phase starts with a few Normal young collections that promote objects into the old generation. The transition to the space-reclamation starts when the old generation occupancy reaches a certain threshold.
-Concurrent Start: Starts the marking process in addition to performing a Normal young collection. Concurrent marking determinates
all currently reachable (live) objects in the old generation regions to be kept for the following space-reclamation phase.
-Remark: It finalizes the marking itself, performs global reference processing and class unloading, reclaims completely empty regions
and cleans up internal data structures.
-Cleanup: Determines whether a space-reclamation phase will actually follow. If a space-reclamation phase follows, the young-only phase
completes with a single Prepare Mixed young collection.&lt;/p&gt;
&lt;h2&gt;Space Reclamation Phase&lt;/h2&gt;
&lt;p&gt;Consists of multiple Mixed collections that in adition to young generation regions, also evacuate live objects of sets of old generation regions.
The space-reclamation phase ends when G1 determines that evacuating more old generation regions wouldn’t yield enough free space worth the effort.&lt;/p&gt;
&lt;p&gt;After the space-reclamation, the collection cycle restarts with another young-only phase. As backup, if the application runs out of memory while gathering liveness information, G1 performs an in-place-stop-the world full heap compaction (Full GC) like other collectors.&lt;/p&gt;
&lt;h2&gt;Garbage Collection Pauses and Collection Set&lt;/h2&gt;
&lt;p&gt;G1 performs garbage collections and space reclamation in the stop-the-world-pauses. Live objects are typically copied from source regions to one or more destination regions in the heap, and existing references to these moved objects are adjusted. The collection set is the set of source regions
to reclaim space from, the collection set consists of different kinds of regions, in the young phase for example, the collection is from humongous regions with objects that could potentially be reclaimed.&lt;/p&gt;
&lt;h2&gt;Garbage-First Internals&lt;/h2&gt;
&lt;p&gt;This section describes some important details of the Garbage-First (G1) garbage collector. When resizing the Java heap, using &lt;strong&gt;-XX:InitialHeapSize&lt;/strong&gt; as  the minimum Java heap size,  and &lt;strong&gt;-XX:MaxHeapSize&lt;/strong&gt; as the maximum Java heap size, &lt;strong&gt;-XX:MaxHeapFreeRatio&lt;/strong&gt; for determining the maximum percentage of free memory after resizing.&lt;/p&gt;
&lt;h2&gt;Young-Only Phase Generation Sizing&lt;/h2&gt;
&lt;p&gt;G1 always sizes the young generation at the end of a normal young collection for the next mutator phase. G1 meet the pause time goals using &lt;strong&gt;-XX:MaxGCPauseTimeMillis&lt;/strong&gt; and &lt;strong&gt;-XX:PauseTimeIntervalMillis&lt;/strong&gt; based on long-term observations of actual pause time. It takes into account how long it took young generations of similar size to evecuate.
if not otherwise constrained, then G1 adaptively sizes the young generation size between &lt;strong&gt;-XX:G1NewSizePercent&lt;/strong&gt; and &lt;strong&gt;-XX:G1MaxNewSizePercent&lt;/strong&gt; determine to meet pause-time.&lt;/p&gt;
&lt;h2&gt;Space-Reclamation Phase Generation Sizing&lt;/h2&gt;
&lt;p&gt;During the space-reclamation phase, G1 tries to maximize the amount of space that is reclaimed in the old generation in a single garbage collection pause. The size of the young generation is set to the minimum allowed, typically as determied by &lt;strong&gt;-XX:G1NewSizePercent&lt;/strong&gt;.
In each mixed collection in this phase, G1 selects a set of regions from the collection set candidates to add to the collection set.It consist of three parts, a minimum set of old generation regions and it is determined by the number of regions in the collection set candidates divided by the length of the Space-Reclamation phase determined by &lt;strong&gt;-XX:G1MixedGCCountTarget&lt;/strong&gt;. It also adds old generation regions from the collection set candidates if G1 predicts that after collecting the minimum set there will be time left. A set of  optional collection set regions that G1 evacuates incrementally after the other two parts have been evacuated and there is time left in this pause.
The Space-Reclamation phase ends when the remaining amount of space that can be reclaimed in the collection set candidate regions is less than the percentage set by &lt;strong&gt;-XX:G1HeapWastePercent&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;Periodic Garbage Collections&lt;/h2&gt;
&lt;p&gt;If there is no garbage collection for a long time, the VM may hold on to a large amount of unused memery for a long time that could be used elsewhere. To avoid this , G1 can be forced to do regular garbage collection using the &lt;strong&gt;-XX:PeriodicGCInterval&lt;/strong&gt;, if the amount of time passed and if there is no concurrent cycle in progress, G1 triggers additional garbage collections, for example in the Young-Only phase starts a concurrent marking using a Concurrent Start pause if &lt;strong&gt;-XX:-G1PeriodicGCInvokesConcurrent&lt;/strong&gt; was specified.
The &lt;strong&gt;-XX:G1PeriodicGCSystemLoadThreshold&lt;/strong&gt; option may be used to refine whether a garbage collection is triggered.&lt;/p&gt;
&lt;h2&gt;Determining Initial Heap Occupancy&lt;/h2&gt;
&lt;p&gt;The Initiating Heap Occupancy Percent (IHOP) is the threshold at which an Initial Mark collection is triggered and it is defined as a percentage of the old generation size.
An optional IHOP is defined in the G1 by observing how long marking takes abd how much memory is typically allocated in the old generation during marking cycles, the feature is called Adaptive IHOP and the option &lt;strong&gt;-XX:InitiatingHeapOccupancyPercent&lt;/strong&gt; determines the initial value as a percentage of the size of the current old generation as long as there aren’t enough observations to make good prediction, turn off this behavior of G1 using the option XX:-G1UseAdaptiveIHOP. IHOP tries to set the Initiating Heap Occupancy so that the first mixed garbage collection of the space-reclamation phase starts when the old generation occupacy is at a current maximum old generation size minus the value of
&lt;strong&gt;-XX:G1HeapReservePercent&lt;/strong&gt; as the extra buffer.&lt;/p&gt;
&lt;h2&gt;Marking&lt;/h2&gt;
&lt;p&gt;G1 marking uses an algorithm called Snapshot-At-The-Beginning (SATB). It takes virtual snapshot of the heap at the time of the Initial Mark pause, when all objects that were live at the start of marking are considered live for the remainder of marking. This means that objects that become dead during marking are still considered live for the purpuse of the space-reclamation.&lt;/p&gt;
&lt;h2&gt;Humongous Objects&lt;/h2&gt;
&lt;p&gt;Humongous objects are objects larger or equal the size of half a region, the current region size is determined ergonomically, unless set using the &lt;strong&gt;-XX:G1HeapRegionSize&lt;/strong&gt; option.
Generally, humongous objects can be reclaimed only at the end of marking during the Cleanup pause, or during Full GC if they became unreachable.There is, however, a special provision for humongous objects for arrays of primitives types for example, bool, all kinds of integers, and floating point values.G1 tries to reclaim humongous objects if they are not referenced by many objects. This behavior is enable by default, you can disable it with the option &lt;strong&gt;-XX:G1EagerReclaimHumongousObjects&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;Ergonomic Defaults for G1 GC&lt;/h2&gt;
&lt;p&gt;This topic provides an overview of the most important defaults specific to G1 and their default values.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;left&quot;&gt;Option and Default Value&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:MaxGCPauseMillis=200&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;The goal for the maximum pause time.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-------------------------------&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-------------------------------------------&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:GCPauseTimeInterval=ergo&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;The goal for the maximum pause time interval. By default&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;G1 doesn’t set any goal, allowing G1 to perform garbage&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;collections back-to-back in extreme cases.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-------------------------------&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-------------------------------------------&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:ParallelGCThreads=ergo&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;The maximum number of threads used for parallel work&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;during garbage collection pauses. This is derived from&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;the number of available threads of the computer that the&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;VM runs.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;At the start of every pause, the maximum number of threads&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;used is further constrained by the maximum total heap size&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;G1 will not use more than one thread&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;per-XX:HeapSizePerGCThread amount of Java heap capacity.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-------------------------------&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-------------------------------------------&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:ConcGCThreads=ergo&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;The maximum number of threads used for concurrent work.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;By default this value is -XX:ParallelGCThreads.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-------------------------------&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-------------------------------------------&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:+G1UseAdaptiveIHOP&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;Defaults for controlling the initiating heap occupancy&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;indicate.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;XX:InitiatingHeapOccupancyPercent:45&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;that adaptive determination of that value is turned on, and&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;that for the first few collection cycles G1 will use an&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;occupancy of 45% of the old generation as mark start&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;threshold.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-------------------------------&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-------------------------------------------&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:G1HeapRegionSize=ergo&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;The set of the heap region size based on initial and maximum&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;heap size. So that heap contains roughly 2048 heap regions.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;The size of a heap region can vary from 1 to 32 MB, and must&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;be power of 2.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-------------------------------&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-------------------------------------------&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:G1NewSizePercent=5&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;The size of the young generation in total, which varies&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;between&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:G1MaxNewSizePercent=60&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;these two values as percentages of the current Java Heap in&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;use.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-------------------------------&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-------------------------------------------&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:G1HeapWastePercent=5&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;The allowed unreclaimed space in the collection&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;set candidates as a percentage. G1 stops the&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;space-reclamation phase if the free&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;space in the collection set candidates is lower than that.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-------------------------------&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-------------------------------------------&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:G1MixedGCCountTaeget=8&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;The expected length of the space-reclamation phase in a number&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;of collections.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-------------------------------&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-------------------------------------------&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;XX:G1MixedGCLiveThresholdPercet=85&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;Old generation regions with higher live objects occupancy than&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;this percentage aren’t collected in this space-reclamation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;phase.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</content:encoded></item><item><title><![CDATA[Available Collectors]]></title><description><![CDATA[Available Collectors The Java HotSpot VM includes three diffent types of collectors, each with different
performance characteristics…]]></description><link>https://github.com/BrahianVT/available-collectors/</link><guid isPermaLink="false">https://github.com/BrahianVT/available-collectors/</guid><pubDate>Fri, 02 Jul 2021 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;Available Collectors&lt;/h2&gt;
&lt;p&gt;The Java HotSpot VM includes three diffent types of collectors, each with different
performance characteristics.&lt;/p&gt;
&lt;h2&gt;Serial Collector&lt;/h2&gt;
&lt;p&gt;The serial collector uses a single thread to perform all the garbage collection work
which makes it relatively efficient because there is no communication overhead between threads.&lt;/p&gt;
&lt;p&gt;This is the best option for single processor machines. The serial collector is selected by default on certain hardware and operating system configurations, or can be explicitly enabled with the option &lt;strong&gt;-XX:+UseSerialGC&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;Parallel Collector&lt;/h2&gt;
&lt;p&gt;It’s also known as throughput collector, it’s a generational collector similar to the serial collector. The primary difference between the serial and parallel collectors is that the parallel collector has multiple threads which are used to speed up garbage collection.
The parallel collector is intended for applications with medium-sized to large-sized data sets that are run on multiprocessor hardware. You can enable it by using the &lt;strong&gt;-XX:-UseParallelGC&lt;/strong&gt; option.&lt;/p&gt;
&lt;h2&gt;The Mostly Concurrent Collectors&lt;/h2&gt;
&lt;p&gt;Concurrent Mark Sweep (CMS) collector and Garbage-First (G1) garbage collector are the two mostly concurrent collectors. Mostly concurrent collectors perform some expensive work concurrently to the application.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;G1 garbage collector: This server-style collector is for multiprocessor machines with a large amount of memory. It meets garbage collection pause-time goals with high probability, it can be explicitly enabled using -XX:+UseG1GC.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CMS collector: this collector is for applications that prefer shorter garbage collection pauses and can afford to share processor resources with the garbage collection, this collector is deprecated from JDK 9.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;The Z Garbage Collector&lt;/h2&gt;
&lt;p&gt;It’s a scalable low latency garbage collector. ZGC performs all expensive work concurrently, without stopping the execution of application threads. ZGC is intended for applications which require low latency (less than 10 ms pauses)
and/or use a very large heap. You can enable by using the &lt;strong&gt;-XX:+UseZGC&lt;/strong&gt; option. It’s available from JDK 11.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Factors Affecting Garbage Collection Performance]]></title><description><![CDATA[The two most important factors affecting garbage collection performance are total available memory and proportion to the heap dedicated to…]]></description><link>https://github.com/BrahianVT/factors-Affecting-Garbage-collection-Performance/</link><guid isPermaLink="false">https://github.com/BrahianVT/factors-Affecting-Garbage-collection-Performance/</guid><pubDate>Wed, 30 Jun 2021 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;The two most important factors affecting garbage collection performance are total available memory and proportion to the heap dedicated to young generation.&lt;/p&gt;
&lt;h2&gt;Total Heap&lt;/h2&gt;
&lt;p&gt;The most important factor affecting garbage collection performace is total available memory.
Because collections occur when generations fill up, throughput is inversely proporcional to the amount
of memory available.&lt;/p&gt;
&lt;h2&gt;Heap options affecting generation size&lt;/h2&gt;
&lt;p&gt;A number of options affects generation size.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 564px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/a0fd892faf7dcf611549d74b3c386669/ba4d9/heap.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 30.37974683544304%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAIAAABM9SnKAAAACXBIWXMAAAsTAAALEwEAmpwYAAABGUlEQVQY043LPU/CQBgA4P5ef4OjE44uDETEhRgXgx0ANUE8EmzB0KYNbUPhaGs/7u69611JTRyoiZNsPvujAQMAoJQyyjhwJZUQohQgBHBgwCjncFCykrJSilKCEDJNkzGWZZm2iTYpSbnkBS+Kksi6TAmxfextk22cpwVLiYiITJnkqgZR+r8cx0mSRGvftdEK4RwPjeHjXN/L3dL3z6/uOw+zwau1XEcvZtCfeCiAIK/K+rv5Q2t1WvpUNz2zN+7djHpuYT9/vJ9ddC9vx9eDmT61+iOj++SMrHyxYRE9nGS0RJZnuaFrY3tLd3mVhVk8WXhzO1z5ezeM17gIPmWYljGtQH2dZLzDhmGgN6SkaprmeDw2//YDCkM81osq4kAAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Memory&quot;
        title=&quot;Memory&quot;
        src=&quot;/JPerformance/static/a0fd892faf7dcf611549d74b3c386669/ba4d9/heap.png&quot;
        srcset=&quot;/JPerformance/static/a0fd892faf7dcf611549d74b3c386669/c26ae/heap.png 158w,
/JPerformance/static/a0fd892faf7dcf611549d74b3c386669/6bdcf/heap.png 315w,
/JPerformance/static/a0fd892faf7dcf611549d74b3c386669/ba4d9/heap.png 564w&quot;
        sizes=&quot;(max-width: 564px) 100vw, 564px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In the image the difference between commited space and virtual space in the heap. At initialization of the virtual machine, the entire space for the heap is reserved.The size of the space reserved can be specified with the &lt;strong&gt;-Xmx&lt;/strong&gt; option, If the value of the &lt;strong&gt;-Xms&lt;/strong&gt; parameter is smaller than the value of the &lt;strong&gt;-Xmx&lt;/strong&gt; parameter,then not all of the space that’s reserved is immediately committed to the virtual machine.The uncommitted space is labeled “virtual”. The old generation and young generation, can grow to the limit of the virtual space as needed.&lt;/p&gt;
&lt;p&gt;Some of the parameters are ratios of one part of the heap to another. For example, the parameter &lt;strong&gt;XX:NewRatio&lt;/strong&gt; denotes the relative size of the old generation to the young generation.&lt;/p&gt;
&lt;h2&gt;Default Option Values for Heap Size&lt;/h2&gt;
&lt;p&gt;The virtual machine grows and shrinks the heap at each collection to try to keep the proportion of free space to live objects at each collection within a specific range.&lt;/p&gt;
&lt;p&gt;This target range is set as a percentage by the options &lt;strong&gt;-XX:MinHeapFreeRatio=“minimum”&lt;/strong&gt; and &lt;strong&gt;-XX:MaxHeapFreeRatio=“maximum”&lt;/strong&gt;
and the total size is bounded below by &lt;strong&gt;-Xms”min”&lt;/strong&gt; and above by &lt;strong&gt;-Xmx”max”&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;With these options, if the percent of free space in generation falls below 40%, then the generation expands to maintain 40% free space,up to the maximum allowed size of the generation.&lt;/p&gt;
&lt;h2&gt;Conserving Dynamic Footprint by Minimizing Java Heap Size&lt;/h2&gt;
&lt;p&gt;If you need to minimize the dynamic memory footprint (RAM consumed during execution) for your application, you can do this by minimizing the Java heap size. Minimize Java heap size by lowering the values of the options &lt;strong&gt;“-XX:MaxHeapFreeRation”&lt;/strong&gt; (default 70%) and &lt;strong&gt;-XX:MinHeapFreeRatio&lt;/strong&gt;(default 40%). Lowering &lt;strong&gt;-XX:MaxHeapFreeRatio&lt;/strong&gt; and &lt;strong&gt;-XX:MinHeapFreeRatio&lt;/strong&gt; by 10% has shown
to successfully reduce the heap size without too much performace degradation.&lt;/p&gt;
&lt;h2&gt;The Young Generation&lt;/h2&gt;
&lt;p&gt;The second factor affecting garbage collection performance is the proportion of the heap dedicated to the young generation, the bigger the young generation, the less often minor collections occur.&lt;/p&gt;
&lt;h3&gt;Young Generation Size Options&lt;/h3&gt;
&lt;p&gt;By default, the young generation size is control by the option &lt;strong&gt;-XX:NewRatio&lt;/strong&gt;, setting &lt;strong&gt;-XX:NewRatio=3&lt;/strong&gt; means the ratio between the young and old generation is 1:3. The options &lt;strong&gt;-XX:NewSize&lt;/strong&gt; and &lt;strong&gt;-XX:MaxNewSize&lt;/strong&gt; bound young generation size from below and above.&lt;/p&gt;
&lt;h2&gt;Survivor Space Sizing&lt;/h2&gt;
&lt;p&gt;You can use the option &lt;strong&gt;-XX:SurvivorRatio&lt;/strong&gt; to tune the size of the survivor spaces, for example &lt;strong&gt;-XX:SurvivorRatio=6&lt;/strong&gt; sets the ratio between eden and a survivor space to 1:6.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;left&quot;&gt;Option&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;Default Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:NewRatio&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:NewSize&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;1310 MB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:MaxNewSize&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;not limited&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:SurvivorRatio&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The maximum size of the young generation is calculated from the maximum size of the total heap and the value of the &lt;strong&gt;-XX:NewRatio&lt;/strong&gt; parameter.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Garbage Collector implementation]]></title><description><![CDATA[The garbage collection is the principal bottleneck, it’s useful to understand some aspects of the implementation. Garbage collectors make…]]></description><link>https://github.com/BrahianVT/garbage-collector-impl/</link><guid isPermaLink="false">https://github.com/BrahianVT/garbage-collector-impl/</guid><pubDate>Sat, 26 Jun 2021 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;The garbage collection is the principal bottleneck, it’s useful to understand some aspects of the implementation. Garbage collectors make assumptions about the way applications use objects, and these are reflected in tunable parameters that can be adjusted for improved performance without sacrificing the power of the abstraction.&lt;/p&gt;
&lt;h2&gt;Generational Garbage Collection&lt;/h2&gt;
&lt;p&gt;An object is considered garbage and its memory can be reused by the VM when it can no longer be reached from any reference of any other live object in the running program.&lt;/p&gt;
&lt;p&gt;The JVM incorporates a number of different garbage collection algorithms that all use a technique called generational collection. The most important property is the weak generational hypothesis, which states that most objects survive for only a short period of time.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 543px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/b82c510e3bc3b18dccd4abfe1a4ea291/29579/blue.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 65.82278481012659%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAAsTAAALEwEAmpwYAAABSElEQVQoz52Q3U7CQBBG+/5PQ4BLL0wkFig1GBMklrRQaLfdbv9tLd3ZGdNGlKiJ4JfJXuzOyXeyGgAgIhHt+liWFYYhEWEfIkqSxLZty7IcxwEAOgURtbIsq7cGAJQCdcr5EhH9vEFEANBCka62EaGSHd8tAYCU8k9YSqltPW5anAilhM/aS5o7eM/E0hZE2Jtfqe0y8bCJiNR586XaLhOmFXXa8A/tIF6cYLhW294Hxgsn7J7x2t++N5b6mhOpsm5EUbetVEq1UiLSx5zB2M8XvFg+DeeHm0d/bBxGhjdZ8WMridS3HqXUL9r63ByZwdDwxgt/MHMH0+1sHTy7YuNnTpA7QR6mVZy/BnGeFHVa1IeosFlWN8emabQ0y24n+p0+n0yNvc8ZT1wmth7f+ZHLhMuEF8ZBFPvdmTCeeGHshXGS5lVVvQOpveyz75aqyQAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Memory&quot;
        title=&quot;Memory&quot;
        src=&quot;/JPerformance/static/b82c510e3bc3b18dccd4abfe1a4ea291/29579/blue.png&quot;
        srcset=&quot;/JPerformance/static/b82c510e3bc3b18dccd4abfe1a4ea291/c26ae/blue.png 158w,
/JPerformance/static/b82c510e3bc3b18dccd4abfe1a4ea291/6bdcf/blue.png 315w,
/JPerformance/static/b82c510e3bc3b18dccd4abfe1a4ea291/29579/blue.png 543w&quot;
        sizes=&quot;(max-width: 543px) 100vw, 543px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;
The blue area in  the image is the typical distribution for the lifetimes of objects.The x-axis is the total bytes in objects with the corresponding lifetime.The sharp peak at the the left represents objects that be reclaimed shortly after being allocated so it focus in the assumption that a majority of objects “die young”.&lt;/p&gt;
&lt;h3&gt;Generations&lt;/h3&gt;
&lt;p&gt;To optimaze for this scenario, memory is managed in  generations(memory pools holding objects of different ages).
Garbage collection occurs in each generation when the generation fills up.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 456px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/9a70a64d916e81165e93bd1f5b256c7e/7f664/memorySections.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 27.21518987341772%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAIAAADKYVtkAAAACXBIWXMAAAsTAAALEwEAmpwYAAABJklEQVQY0yXIUU+CQAAAYH50r/2BXtxaD64Hc3OGazKmqRMljdlEJMzUpcLQhqBMUOHgOE7ibKvH76MIISlJU5ISQsiF/JNcSBjCCCEUxyiO8fnsef5qvcZJgnHyFwkAASXIgjJXtq6lGqqyUmRdnu8W4Y/PdqSbh0a++sbwckuciZ/aTNtwQ62pGIOlrZony/GobDHLtJipPuUHfEWs0DzdVtp+esjXXq8y5UzxJVfts91xZ7gYLc17pksLam95/LLAzsNU4blQapa4PsdJXGPUqL/X+5r4fdLzNf76jr195HNs76kl1YRxW5yVu5OqtO5MtiPdmRtHytyazsFxj65hbT6mY9ux/cB33L29dzwAPRD6AQQBBGEEQggRhvEZIhwhHMX4F3/W/TUz3Y5xAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Memory&quot;
        title=&quot;Memory&quot;
        src=&quot;/JPerformance/static/9a70a64d916e81165e93bd1f5b256c7e/7f664/memorySections.png&quot;
        srcset=&quot;/JPerformance/static/9a70a64d916e81165e93bd1f5b256c7e/c26ae/memorySections.png 158w,
/JPerformance/static/9a70a64d916e81165e93bd1f5b256c7e/6bdcf/memorySections.png 315w,
/JPerformance/static/9a70a64d916e81165e93bd1f5b256c7e/7f664/memorySections.png 456w&quot;
        sizes=&quot;(max-width: 456px) 100vw, 456px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;
At the startup, the VM reserves the entire Java heap in the address space, but doesn’t allocate any physical memory for it unless needed, the space is logically divided into young and old generations.&lt;/p&gt;
&lt;p&gt;The Young generation consists of eden and two survivor spaces. Most objects are initially allocated in the eden. One survior space is empty at any time, and serves as the destination of live objects in eden and the other survivor space during garbage collection, after a garbage collection, eden and the survivor space are empty.In the next garbage collection, the purpose of the two survivor spaces are exchanged. The one space recently filled is a source of live objects that copied into the other survivor space.Objects are copied between survivor spaces in this way until they’ve been copied a certain number of times or there isn’t enough space left there. These objects are copied into the old region. This process is also called aging.&lt;/p&gt;
&lt;h3&gt;Performance Considerations&lt;/h3&gt;
&lt;p&gt;The primary measures of the garbage collection are throughput and latency.
.Throughput is the percentage of total time not spent in garbage collection considered over long periods of time.
.Latency is the responsiveness of an application. Consider the right metric for a web server to be throughput because pauses during garbage collection may be tolerable, obscured by network latencies. However in an interactive graphics program, even short pauses affect the user experience.&lt;/p&gt;
&lt;h3&gt;Throughput and Footprint Measurement&lt;/h3&gt;
&lt;p&gt;Throughput and footprint are best measured using metrics particular to the application.
For example, the throughput of a web server may be tested using a client load generator.
Also in the VM logs with the command &lt;strong&gt;“-verbose:gc”&lt;/strong&gt; prints information about the heap andgarbage collection at each collection for example:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;[15,651s][info ][gc] GC(36) Pause Young (G1 Evacuation Pause) 239M-&gt;57M(307M) (15,646s, 15,651s) 5,048ms.
[16,162s][info ][gc] GC(37) Pause Young (G1 Evacuation Pause) 238M-&gt;57M(307M) (16,146s, 16,162s) 16,565ms.
[16,367s][info ][gc] GC(38) Pause Full (System.gc()) 69M-&gt;31M(104M) (16,202s, 16,367s) 164,581ms&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The output shows two young generations followeb by a full collection bacause of the &lt;strong&gt;“System.gc()”&lt;/strong&gt; call.&lt;/p&gt;
&lt;p&gt;The first line shows 239M-&gt;57M(307M), which means that 239M were usef before the GC and the GC cleared up most of the memory, but 57MB survived. The heap size is 307M, note that the full GC shrinks the heap from 307 MB to 104 MB, the start and end times for the GC are logged as well as the duration (end-start).&lt;/p&gt;</content:encoded></item><item><title><![CDATA[JVM Ergonomics]]></title><description><![CDATA[Is the process by which the Java Virtual Machine and garbage collection heuristics, improve application performance. The JVM provides…]]></description><link>https://github.com/BrahianVT/jvm-ergonomics/</link><guid isPermaLink="false">https://github.com/BrahianVT/jvm-ergonomics/</guid><pubDate>Fri, 25 Jun 2021 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Is the process by which the Java Virtual Machine and garbage collection heuristics, improve application performance.&lt;/p&gt;
&lt;p&gt;The JVM provides platform-dependent default selections for the garbage collector, heap size and runtime compiler. These selections match the needs of different types of applications while requiring less command-line tuning. In addition, behavior-based tuning dynamically optimizes the sizes of the heap to meet a specified behavior of the application.&lt;/p&gt;
&lt;h2&gt;Garbage Collector, Heap, and Runtime Compiler Defaults Selections&lt;/h2&gt;
&lt;p&gt;These are important garbage collector, heap size, and runtime compiler default selections:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Garbage-First (G1) collector&lt;/li&gt;
&lt;li&gt;The maximum number of GC threads is limited by the heap size and availible CPU resources&lt;/li&gt;
&lt;li&gt;Initial heap size of 1/64 of physical memory&lt;/li&gt;
&lt;li&gt;Maximum heap size of 1/4 of physical memory&lt;/li&gt;
&lt;li&gt;Tiered compiler, using both C1 and C2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Java HotSpot VM garbage collectors can be configured to preferentially meet one of the next goals:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Maximum pause-time goal&lt;/li&gt;
&lt;li&gt;Application throughput&lt;/li&gt;
&lt;li&gt;Footprint&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Maximum Pause-Time Goal&lt;/h3&gt;
&lt;p&gt;The pause time is the duration which the garbage collector stops the application and recovers space that’s no longet in use.
The intent of the maximum pause-time goal is to limit the longest of these pauses. An average time for pauses and a variance on that average is maintained by the garbage collector.
The average is taken for the start of the execution, but it’s weighted so that more recent pauses count more heavily. If the average plus the variance of the pause-time is greater than the maximum pause-time goal, then the garbage collector
considers that the goal isn’t being met. The maximum pause-time goal is specified with the command option &lt;em&gt;“XX:MAXGCPauseMillis=nnn”&lt;/em&gt;.
The garbage collector adjunts the Java heap size and other parameters related to garbage collection in an attempt to keep garbage collection
pauses shorter than &lt;em&gt;“nnn”&lt;/em&gt;.&lt;/p&gt;
&lt;h3&gt;Throughput Goal&lt;/h3&gt;
&lt;p&gt;The throughput goal is measured in terms of the time spent collecting garbage and the time spent outside of the garbage collection.
The goal is specified by the command-line option &lt;em&gt;“-XX:GCTimeRatio=nnn”&lt;/em&gt;. The ratio of the garbage collection time to application is &lt;em&gt;1/(1+nnn)&lt;/em&gt;.
For example, &lt;em&gt;“-XX:GCTimeRatio=19”&lt;/em&gt; sets a goal of 1/20th or 5% of the total time for garbage collection.
The time spent in garbage collection is the total time for all garbage collection induced pauses.If the throughput goal isn’t being met, then one possible action for the garbage collector is to increase the size of the heap so the time spent in the appplication between collection pauses can be longer.&lt;/p&gt;
&lt;h3&gt;Footprint&lt;/h3&gt;
&lt;p&gt;If the throughput and maximum pause-time goals have been met, then garbage collector reduces the size of the heap until one goal can’t be met.&lt;/p&gt;
&lt;h3&gt;Tuning Strategy&lt;/h3&gt;
&lt;p&gt;The heap grows or shrinks to a size that supports the chosen throughput goal. Don’t choose a maximum value for the heap unless you know that you need a heap greater than the default maximum heap size.
If the heap grows to its maximum size and the throughput goal isn’t being met, then the maximum heap size is too small for the throughput goal. Set the maximum heap size to a value that’s close to the total physical memory on the platform,
but doesn´t cause swapping of the application.Execute the application again. If the throughput goal isn’t met, then the goal for the application time is too high for the available memory on the platform.
If the throughput goal can be met, but the pauses are too long, then select a maximum pause-time goal. Choosing a maximum pause-time goal may mean that your throughput goal won’t be met, so choose values that are an acceptable compromise for
the application.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[What is a Garbage Collector]]></title><description><![CDATA[The garbage collector (GC) automatically manages the memory in our Java applications, basically it helps us to avoid to deal with the memory…]]></description><link>https://github.com/BrahianVT/garbage-collector/</link><guid isPermaLink="false">https://github.com/BrahianVT/garbage-collector/</guid><pubDate>Sat, 19 Jun 2021 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;The garbage collector (GC) automatically manages the memory in our Java applications, basically it helps us to avoid to deal with the memory by ourselves.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The garbage collector is responsible for the following operations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Allocates from and gives back memory to the operating system&lt;/li&gt;
&lt;li&gt;Hands out that memory to the application as it requests it&lt;/li&gt;
&lt;li&gt;Determines which parts of the memory is still use by the application&lt;/li&gt;
&lt;li&gt;Reclaims the unused memory for reuse by the application&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Java HotSpot garbage collectors employ various techniques to improve the efficiency of these operations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use generational scavenging in conjuntion with aging to concentrate their efforts on areas in the heap that most likely contain a lot of reclaimable memory areas.&lt;/li&gt;
&lt;li&gt;Use multiple threads to aggressively make operations on parallel, or performe some long-running operations in the background concurrent application&lt;/li&gt;
&lt;li&gt;Try to recover larger contiguous free memory by compacting live objects&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Why Does it Matter?&lt;/h2&gt;
&lt;p&gt;The Java HotSpot VM provides a selection of garbage collection algorithms to choose from. &lt;strong&gt;When it does matter?&lt;/strong&gt; The application can perform well in the presence of garbage collection with pauses of modest frequency and duration.
However, specifically for a large class of applications, those with large amounts of data(multiple gigabytes), many thread and high transaction rates it can be the opposite.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 564px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/JPerformance/static/2ea2871e44f01f2141fd8906b76ef8ed/ba4d9/gcExample.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 63.92405063291139%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAAsTAAALEwEAmpwYAAABrklEQVQoz21S227bMAz1//9f+1BgSVbsUseXWLZEkTwkNShZA2woQQgkIOpcxCEiiGiapnVdaimViKiKSK39fBa1VmYWESIS5lprznlorYnIdVwKS6bCXCHsqg4093CPiPZViMhARB/jxzxvIojWqloRIWFREWFTNVUwQwQsvQUMWKZpul47sqrmXNZbaXeQiAYLhpGiAoz7hJuHueExfOwpbbeBmad5bo7ldtSKMHvyjGjmAYuqIAUDpMqmCPt2Of349XNw95xz11DLujOzdQD7X2pEc+8mKELgt3TM6zao6p5Sa80NWmnLmukvR4d55/G1Ycw8mFnqw/2GQ02okG6HFu5Cwz6zOx8tnkSilDIA2Pf9+Z6bmRCklsIpa8paxVnc8MkFXdc6Lx+/fw/n83ld13/kteaOgECqcM25HgelvaRD9qxb5kx4eX17eX0bLpeLiPh9GZ7xcKhX7mEapgZRpkcylffv76fTecg5T9MkIiklIiqlzPMMYFmWco/xeoXZNE05ZyIax6sBaduOY+9Lsm3b6XQax/HhhJl18Z9cDGit2f3/IwL3FjAz/wM7HvTWhnx9CwAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Alt Text&quot;
        title=&quot;Gargabe Collector performance&quot;
        src=&quot;/JPerformance/static/2ea2871e44f01f2141fd8906b76ef8ed/ba4d9/gcExample.png&quot;
        srcset=&quot;/JPerformance/static/2ea2871e44f01f2141fd8906b76ef8ed/c26ae/gcExample.png 158w,
/JPerformance/static/2ea2871e44f01f2141fd8906b76ef8ed/6bdcf/gcExample.png 315w,
/JPerformance/static/2ea2871e44f01f2141fd8906b76ef8ed/ba4d9/gcExample.png 564w&quot;
        sizes=&quot;(max-width: 564px) 100vw, 564px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The read line (at top) is an application spending only 1% of the time in a garbage collection on an uniprocessor system. The magenta line shows a 10% of the time in garbage collection.&lt;/p&gt;
&lt;p&gt;The main problem may become with large bottlenecks when scaling up to large systems, for example the previous problems with a waste of 10% of the time with a single thread can lead to a 75% of throughput loss when scaling up to 32 processors.&lt;/p&gt;</content:encoded></item></channel></rss>